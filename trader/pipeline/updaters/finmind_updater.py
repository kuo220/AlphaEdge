import datetime
import json
import sqlite3
import time
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple, Union

import pandas as pd
from loguru import logger

from trader.config import (
    BROKER_TRADING_METADATA_PATH,
    DB_PATH,
    FINMIND_DOWNLOADS_PATH,
    SECURITIES_TRADER_INFO_TABLE_NAME,
    STOCK_INFO_WITH_WARRANT_TABLE_NAME,
    STOCK_TRADING_DAILY_REPORT_TABLE_NAME,
)
from trader.pipeline.cleaners.finmind_cleaner import FinMindCleaner
from trader.pipeline.crawlers.finmind_crawler import FinMindCrawler
from trader.pipeline.loaders.finmind_loader import FinMindLoader
from trader.pipeline.updaters.base import BaseDataUpdater
from trader.pipeline.utils import FinMindDataType, UpdateStatus
from trader.pipeline.utils.sqlite_utils import SQLiteUtils
from trader.utils.log_manager import LogManager
from trader.utils import TimeUtils

"""
FinMind è³‡æ–™æ›´æ–°å™¨

æ”¯æ´æ›´æ–°ä»¥ä¸‹ä¸‰ç¨®è³‡æ–™ï¼š
1. å°è‚¡ç¸½è¦½(å«æ¬Šè­‰) (TaiwanStockInfoWithWarrant) - ä¸€æ¬¡æ€§æ›´æ–°å…¨éƒ¨è³‡æ–™
2. è­‰åˆ¸å•†è³‡è¨Šè¡¨ (TaiwanSecuritiesTraderInfo) - ä¸€æ¬¡æ€§æ›´æ–°å…¨éƒ¨è³‡æ–™
3. ç•¶æ—¥åˆ¸å•†åˆ†é»çµ±è¨ˆè¡¨ (TaiwanStockTradingDailyReportSecIdAgg) - éœ€è¦æŒ‡å®šæ—¥æœŸç¯„åœ

æ›´æ–°æ–¹æ³•ï¼š
- update_stock_info_with_warrant() - æ›´æ–°å°è‚¡ç¸½è¦½
- update_broker_info() - æ›´æ–°è­‰åˆ¸å•†è³‡è¨Š
- update_broker_trading_daily_report(start_date, end_date, stock_id, securities_trader_id) - æ›´æ–°åˆ¸å•†åˆ†é»çµ±è¨ˆ
- update_broker_trading_daily_report_batch(start_date, end_date) - æ‰¹é‡æ›´æ–°åˆ¸å•†åˆ†é»çµ±è¨ˆï¼ˆloop åˆ¸å•†ã€è‚¡ç¥¨ï¼Œä¸€æ¬¡æ€§æŸ¥è©¢æ•´å€‹æ—¥æœŸç¯„åœï¼‰
- update_all() - æ›´æ–°æ‰€æœ‰ FinMind è³‡æ–™
- update(data_type, **kwargs) - é€šç”¨æ›´æ–°æ–¹æ³•ï¼Œå¯æŒ‡å®šè³‡æ–™é¡å‹
"""


class FinMindUpdater(BaseDataUpdater):
    """FinMind Updater"""

    def __init__(self):
        super().__init__()

        # SQLite Connection
        self.conn: Optional[sqlite3.Connection] = None

        # ETL
        self.crawler: FinMindCrawler = FinMindCrawler()
        self.cleaner: FinMindCleaner = FinMindCleaner()
        self.loader: FinMindLoader = FinMindLoader()

        # API Quota è¿½è¹¤ï¼ˆåˆå§‹å€¼ï¼Œæœƒåœ¨ setup ä¸­å‹•æ…‹ç²å–ï¼‰
        self.api_quota_limit: int = 20000  # æ¯å°æ™‚æœ€å¤§ API èª¿ç”¨æ¬¡æ•¸ï¼ˆé è¨­å€¼ï¼‰
        self.api_call_count: int = 0  # ç•¶å‰å°æ™‚çš„ API èª¿ç”¨æ¬¡æ•¸
        self.quota_reset_time: float = time.time() + 3600  # ä¸‹æ¬¡é‡ç½®æ™‚é–“ï¼ˆ1å°æ™‚å¾Œï¼‰

        # Broker trading metadata æ–‡ä»¶è·¯å¾‘ï¼ˆè¨˜éŒ„æ¯å€‹ broker_id å’Œ stock_id çš„æ—¥æœŸç¯„åœï¼‰
        self.broker_trading_metadata_path: Path = BROKER_TRADING_METADATA_PATH

        self.setup()

    def setup(self, *args, **kwargs) -> None:
        """Set Up the Config of Updater"""

        # DB Connect
        if self.conn is None:
            self.conn = sqlite3.connect(DB_PATH)

        # è¨­å®š log æª”æ¡ˆå„²å­˜è·¯å¾‘
        LogManager.setup_logger("update_finmind.log")

        # å‹•æ…‹ç²å– API quota é™åˆ¶
        try:
            if self.crawler.api and hasattr(self.crawler.api, "api_usage_limit"):
                self.api_quota_limit = self.crawler.api.api_usage_limit
                logger.info(
                    f"FinMind API quota limit retrieved: {self.api_quota_limit} calls per hour"
                )
            else:
                logger.warning(
                    f"Could not retrieve API quota limit from FinMind API. Using default: {self.api_quota_limit}"
                )
        except Exception as e:
            logger.warning(
                f"Error retrieving API quota limit: {e}. Using default: {self.api_quota_limit}"
            )

    def update(
        self,
        data_type: Optional[Union[str, FinMindDataType]] = None,
        start_date: Optional[Union[datetime.date, str]] = None,
        end_date: Optional[Union[datetime.date, str]] = None,
        stock_id: Optional[str] = None,
        securities_trader_id: Optional[str] = None,
        **kwargs,
    ) -> None:
        """
        é€šç”¨æ›´æ–°æ–¹æ³•

        Args:
            data_type: è³‡æ–™é¡å‹ï¼Œå¯é¸å€¼ï¼š
                - FinMindDataType.STOCK_INFO æˆ– "stock_info": æ›´æ–°å°è‚¡ç¸½è¦½
                - FinMindDataType.BROKER_INFO æˆ– "broker_info": æ›´æ–°è­‰åˆ¸å•†è³‡è¨Š
                - FinMindDataType.BROKER_TRADING æˆ– "broker_trading": æ›´æ–°åˆ¸å•†åˆ†é»çµ±è¨ˆ
                - "all" æˆ– None: æ›´æ–°æ‰€æœ‰è³‡æ–™
            start_date: èµ·å§‹æ—¥æœŸï¼ˆåƒ…ç”¨æ–¼ BROKER_TRADINGï¼‰
            end_date: çµæŸæ—¥æœŸï¼ˆåƒ…ç”¨æ–¼ BROKER_TRADINGï¼‰
            stock_id: è‚¡ç¥¨ä»£ç¢¼ï¼ˆå¯é¸ï¼Œåƒ…ç”¨æ–¼ BROKER_TRADINGï¼‰
            securities_trader_id: åˆ¸å•†ä»£ç¢¼ï¼ˆå¯é¸ï¼Œåƒ…ç”¨æ–¼ BROKER_TRADINGï¼‰
        """
        # è™•ç† "all" æˆ– None çš„æƒ…æ³
        if data_type is None or (
            isinstance(data_type, str) and data_type.lower() == "all"
        ):
            self.update_all(
                start_date=start_date,
                end_date=end_date,
                stock_id=stock_id,
                securities_trader_id=securities_trader_id,
            )
            return

        # å°‡å­—ä¸²è½‰æ›ç‚º Enumï¼ˆå‘å¾Œå…¼å®¹ï¼‰
        if isinstance(data_type, str):
            data_type_str: str = data_type.upper()
            try:
                data_type = FinMindDataType(data_type_str)
            except ValueError:
                # å˜—è©¦å°å¯«å½¢å¼ï¼ˆæ›´å‹å¥½çš„ç”¨æˆ¶è¼¸å…¥ï¼‰
                data_type_str_lower: str = data_type.lower()
                type_mapping: Dict[str, FinMindDataType] = {
                    dt.value.lower(): dt for dt in FinMindDataType
                }
                if data_type_str_lower in type_mapping:
                    data_type = type_mapping[data_type_str_lower]
                else:
                    raise ValueError(
                        f"Unknown data_type string: {data_type}. "
                        f"Supported strings: {[dt.value.lower() for dt in FinMindDataType]}, 'all'"
                    )

        if data_type == FinMindDataType.STOCK_INFO:
            self.update_stock_info_with_warrant()
        elif data_type == FinMindDataType.BROKER_INFO:
            self.update_broker_info()
        elif data_type == FinMindDataType.BROKER_TRADING:
            if start_date is None or end_date is None:
                raise ValueError(
                    "start_date and end_date are required for BROKER_TRADING"
                )
            self.update_broker_trading_daily_report(
                start_date=start_date,
                end_date=end_date,
                stock_id=stock_id,
                securities_trader_id=securities_trader_id,
            )
        else:
            raise ValueError(
                f"Unknown data_type: {data_type}. "
                f"Supported types: {[dt.name for dt in FinMindDataType]}, 'all'"
            )

    def update_stock_info_with_warrant(self) -> None:
        """æ›´æ–°å°è‚¡ç¸½è¦½(å«æ¬Šè­‰)è³‡æ–™"""

        logger.info("* Start Updating Taiwan Stock Info With Warrant...")

        # Step 1: Crawl
        df: Optional[pd.DataFrame] = self.crawler.crawl_stock_info_with_warrant()
        if df is None or df.empty:
            logger.warning("No stock info with warrant data to update")
            return

        # Step 2: Clean
        cleaned_df: Optional[pd.DataFrame] = self.cleaner.clean_stock_info_with_warrant(
            df
        )
        if cleaned_df is None or cleaned_df.empty:
            logger.warning("Cleaned stock info with warrant data is empty")
            return

        # Step 3: Load
        # ç¢ºä¿ loader æœ‰é€£æ¥
        if self.loader.conn is None:
            self.loader.connect()
        self.loader._load_stock_info_with_warrant()
        if self.loader.conn:
            self.loader.conn.commit()

        logger.info("âœ… Taiwan Stock Info With Warrant updated successfully")

    def update_broker_info(self) -> None:
        """æ›´æ–°è­‰åˆ¸å•†è³‡è¨Šè¡¨è³‡æ–™"""

        logger.info("* Start Updating Broker Info...")

        # Step 1: Crawl
        df: Optional[pd.DataFrame] = self.crawler.crawl_broker_info()
        if df is None or df.empty:
            logger.warning("No broker info data to update")
            return

        # Step 2: Clean
        cleaned_df: Optional[pd.DataFrame] = self.cleaner.clean_broker_info(df)
        if cleaned_df is None or cleaned_df.empty:
            logger.warning("Cleaned broker info data is empty")
            return

        # Step 3: Load
        # ç¢ºä¿ loader æœ‰é€£æ¥
        if self.loader.conn is None:
            self.loader.connect()
        self.loader._load_broker_info()
        if self.loader.conn:
            self.loader.conn.commit()

        logger.info("âœ… Broker Info updated successfully")

    def update_broker_trading_daily_report(
        self,
        stock_id: Optional[str] = None,
        securities_trader_id: Optional[str] = None,
        start_date: Union[datetime.date, str] = None,
        end_date: Union[datetime.date, str] = None,
        skip_processed_check: bool = False,
    ) -> UpdateStatus:
        """
        æ›´æ–°ç•¶æ—¥åˆ¸å•†åˆ†é»çµ±è¨ˆè¡¨è³‡æ–™

        Args:
            start_date: èµ·å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            stock_id: è‚¡ç¥¨ä»£ç¢¼ï¼ˆå¯é¸ï¼Œä¸æä¾›å‰‡è¿”å›æ‰€æœ‰è‚¡ç¥¨ï¼‰
            securities_trader_id: åˆ¸å•†ä»£ç¢¼ï¼ˆå¯é¸ï¼Œä¸æä¾›å‰‡è¿”å›æ‰€æœ‰åˆ¸å•†ï¼‰
            skip_processed_check: æ˜¯å¦è·³éå·²è™•ç†é …ç›®çš„æª¢æŸ¥ï¼ˆé è¨­ Falseï¼‰
                                ç•¶å¾ batch æ–¹æ³•èª¿ç”¨æ™‚æ‡‰è¨­ç‚º Trueï¼Œé¿å…é‡è¤‡æª¢æŸ¥

        Returns:
            UpdateStatus: æ›´æ–°ç‹€æ…‹
                - UpdateStatus.SUCCESS: æˆåŠŸæ›´æ–°
                - UpdateStatus.NO_DATA: æ²’æœ‰è³‡æ–™ï¼ˆAPI è¿”å›ç©ºçµæœï¼‰
                - UpdateStatus.ALREADY_UP_TO_DATE: è³‡æ–™åº«å·²æ˜¯æœ€æ–°
                - UpdateStatus.ERROR: ç™¼ç”ŸéŒ¯èª¤
        """

        logger.info(
            f"* Start Updating Broker Trading Daily Report: {start_date} to {end_date}"
        )

        # å¦‚æœæ²’æœ‰è·³éæª¢æŸ¥ï¼Œä¸”æä¾›äº† stock_id å’Œ securities_trader_idï¼Œæª¢æŸ¥æ˜¯å¦å·²è™•ç†é
        # ç‰¹åˆ¥è™•ç†å–®å€‹æ—¥æœŸçš„æƒ…æ³ï¼ˆstart_date == end_dateï¼‰
        if (
            not skip_processed_check
            and stock_id
            and securities_trader_id
            and start_date
            and end_date
        ):
            # æ¨™æº–åŒ–æ—¥æœŸæ ¼å¼ä»¥ä¾¿æ¯”è¼ƒ
            if isinstance(start_date, str):
                start_date_obj: datetime.date = datetime.datetime.strptime(
                    start_date, "%Y-%m-%d"
                ).date()
            else:
                start_date_obj: datetime.date = start_date

            if isinstance(end_date, str):
                end_date_obj: datetime.date = datetime.datetime.strptime(
                    end_date, "%Y-%m-%d"
                ).date()
            else:
                end_date_obj: datetime.date = end_date

            # å¦‚æœæ˜¯å–®å€‹æ—¥æœŸï¼Œæª¢æŸ¥æ˜¯å¦å·²è™•ç†ï¼ˆå¾ metadata æª¢æŸ¥ï¼‰
            if start_date_obj == end_date_obj:
                date_str: str = start_date_obj.strftime("%Y-%m-%d")

                # å¾ metadata æª¢æŸ¥æ—¥æœŸæ˜¯å¦åœ¨ç¯„åœå…§
                if self._check_date_exists_in_metadata(
                    securities_trader_id=securities_trader_id,
                    stock_id=stock_id,
                    date=start_date_obj,
                ):
                    logger.info(
                        f"Date {date_str} for trader={securities_trader_id}, stock={stock_id} "
                        f"already exists in metadata. Skipping."
                    )
                    return UpdateStatus.ALREADY_UP_TO_DATE

        # å–å¾—è¦é–‹å§‹æ›´æ–°çš„æ—¥æœŸï¼ˆå¾è³‡æ–™åº«æœ€æ–°æ—¥æœŸ+1å¤©é–‹å§‹ï¼Œæˆ–ä½¿ç”¨æä¾›çš„ start_dateï¼‰
        actual_start_date: Union[datetime.date, str] = (
            self.get_actual_update_start_date(default_date=start_date)
        )

        # å¦‚æœå¯¦éš›é–‹å§‹æ—¥æœŸå·²ç¶“è¶…éçµæŸæ—¥æœŸï¼Œå‰‡ä¸éœ€è¦æ›´æ–°
        # çµ±ä¸€è½‰æ›ç‚º datetime.date é€²è¡Œæ¯”è¼ƒ
        if isinstance(actual_start_date, str):
            actual_start_date_obj: datetime.date = datetime.datetime.strptime(
                actual_start_date, "%Y-%m-%d"
            ).date()
        else:
            actual_start_date_obj: datetime.date = actual_start_date

        if isinstance(end_date, str):
            end_date_obj: datetime.date = datetime.datetime.strptime(
                end_date, "%Y-%m-%d"
            ).date()
        else:
            end_date_obj: datetime.date = end_date

        if actual_start_date_obj > end_date_obj:
            logger.info(
                f"No new data to update. Latest date in database is already up to date."
            )
            return UpdateStatus.ALREADY_UP_TO_DATE

        logger.info(f"Updating from {actual_start_date} to {end_date}")

        try:
            # Step 1: Crawl
            df: Optional[pd.DataFrame] = self.crawler.crawl_broker_trading_daily_report(
                stock_id=stock_id,
                securities_trader_id=securities_trader_id,
                start_date=actual_start_date,
                end_date=end_date,
            )
            if df is None or df.empty:
                # è¨˜éŒ„æ›´è©³ç´°çš„è³‡è¨Šï¼ŒåŒ…å« stock_id å’Œ securities_trader_id
                if stock_id and securities_trader_id:
                    logger.debug(
                        f"No broker trading daily report data for stock_id={stock_id}, "
                        f"securities_trader_id={securities_trader_id}, "
                        f"date={actual_start_date} to {end_date}"
                    )
                else:
                    logger.warning(
                        f"No broker trading daily report data to update from {actual_start_date} to {end_date}"
                    )
                return UpdateStatus.NO_DATA

            # Step 2: Clean
            cleaned_df: Optional[pd.DataFrame] = (
                self.cleaner.clean_broker_trading_daily_report(df)
            )
            if cleaned_df is None or cleaned_df.empty:
                logger.warning("Cleaned broker trading daily report data is empty")
                return UpdateStatus.NO_DATA

            # Step 3: Load - å°‡è³‡æ–™ä¿å­˜åˆ°è³‡æ–™åº«
            # ç¢ºä¿ loader æœ‰é€£æ¥
            if self.loader.conn is None:
                self.loader.connect()

            # ç¢ºä¿è³‡æ–™è¡¨å­˜åœ¨
            self.loader.create_missing_tables()

            # å°‡æ¸…ç†å¾Œçš„è³‡æ–™ä¿å­˜åˆ°è³‡æ–™åº«
            # æ³¨æ„ï¼šcleaned_df å·²ç¶“æŒ‰ (securities_trader_id, stock_id) åˆ†çµ„ä¸¦ä¿å­˜åˆ° CSV
            # ç¾åœ¨éœ€è¦å°‡é€™äº›è³‡æ–™ä¹Ÿå¯«å…¥è³‡æ–™åº«
            # æª¢æŸ¥è³‡æ–™åº«ä¸­å·²å­˜åœ¨çš„è³‡æ–™ï¼Œé¿å…é‡è¤‡æ’å…¥
            existing_query: str = f"""
            SELECT DISTINCT stock_id, date, securities_trader_id
            FROM {STOCK_TRADING_DAILY_REPORT_TABLE_NAME}
            """
            try:
                existing_df: pd.DataFrame = pd.read_sql_query(existing_query, self.conn)

                if not existing_df.empty:
                    # å»ºç«‹å·²å­˜åœ¨çš„éµé›†åˆ
                    existing_keys: Set[Tuple[str, str, str]] = set(
                        zip(
                            existing_df["stock_id"].astype(str),
                            existing_df["date"].astype(str),
                            existing_df["securities_trader_id"].astype(str),
                        )
                    )

                    # éæ¿¾å‡ºæ–°è³‡æ–™
                    cleaned_df["_key"] = list(
                        zip(
                            cleaned_df["stock_id"].astype(str),
                            cleaned_df["date"].astype(str),
                            cleaned_df["securities_trader_id"].astype(str),
                        )
                    )
                    mask: pd.Series = ~cleaned_df["_key"].isin(existing_keys)
                    new_df: pd.DataFrame = cleaned_df[mask].drop(columns=["_key"])
                else:
                    new_df: pd.DataFrame = cleaned_df

                # åªæ’å…¥æ–°è³‡æ–™
                if not new_df.empty:
                    # ç¢ºä¿æ¬„ä½é †åºæ­£ç¢º
                    column_order: List[str] = [
                        "securities_trader",
                        "securities_trader_id",
                        "stock_id",
                        "date",
                        "buy_volume",
                        "sell_volume",
                        "buy_price",
                        "sell_price",
                    ]
                    available_columns: List[str] = [
                        col for col in column_order if col in new_df.columns
                    ]
                    new_df = new_df[available_columns]

                    new_df.to_sql(
                        STOCK_TRADING_DAILY_REPORT_TABLE_NAME,
                        self.conn,
                        if_exists="append",
                        index=False,
                    )
                    self.conn.commit()
                    logger.info(
                        f"âœ… Saved {len(new_df)} new records to database "
                        f"({len(cleaned_df) - len(new_df)} duplicates skipped)"
                    )
                else:
                    logger.debug("All data already exists in database, skipping insert")

            except Exception as e:
                logger.warning(
                    f"Error checking existing data: {e}. Will insert all data."
                )
                # å¦‚æœæª¢æŸ¥å¤±æ•—ï¼Œå˜—è©¦ç›´æ¥æ’å…¥ï¼ˆå¯èƒ½æœƒå› ç‚ºé‡è¤‡éµè€Œå¤±æ•—ï¼Œä½†è‡³å°‘å˜—è©¦ï¼‰
                column_order: List[str] = [
                    "securities_trader",
                    "securities_trader_id",
                    "stock_id",
                    "date",
                    "buy_volume",
                    "sell_volume",
                    "buy_price",
                    "sell_price",
                ]
                available_columns: List[str] = [
                    col for col in column_order if col in cleaned_df.columns
                ]
                try:
                    cleaned_df[available_columns].to_sql(
                        STOCK_TRADING_DAILY_REPORT_TABLE_NAME,
                        self.conn,
                        if_exists="append",
                        index=False,
                    )
                    self.conn.commit()
                    logger.info(f"âœ… Saved {len(cleaned_df)} records to database")
                except Exception as insert_error:
                    logger.error(f"Error inserting data to database: {insert_error}")

            # æ›´æ–°å¾Œé‡æ–°å–å¾— Table æœ€æ–°çš„æ—¥æœŸ
            table_latest_date: str = SQLiteUtils.get_table_latest_value(
                conn=self.conn,
                table_name=STOCK_TRADING_DAILY_REPORT_TABLE_NAME,
                col_name="date",
            )
            if table_latest_date:
                logger.info(
                    f"âœ… Broker trading daily report updated successfully. Latest available date: {table_latest_date}"
                )
            else:
                logger.warning("No new broker trading daily report data was updated")
            return UpdateStatus.SUCCESS

        except Exception as e:
            logger.error(
                f"Error updating broker trading daily report: {e}",
                exc_info=True,
            )
            return UpdateStatus.ERROR

    def update_broker_trading_daily_report_batch(
        self,
        start_date: Union[datetime.date, str],
        end_date: Union[datetime.date, str],
    ) -> None:
        """
        æ‰¹é‡æ›´æ–°ç•¶æ—¥åˆ¸å•†åˆ†é»çµ±è¨ˆè¡¨è³‡æ–™ï¼ˆloop åˆ¸å•†ã€è‚¡ç¥¨ï¼‰

        æ­¤æ–¹æ³•æœƒï¼š
        1. Loop æ‰€æœ‰åˆ¸å•† ID
        2. Loop æ‰€æœ‰è‚¡ç¥¨ ID
        3. å°æ¯å€‹ (åˆ¸å•†, è‚¡ç¥¨) çµ„åˆï¼Œä¸€æ¬¡æ€§æŸ¥è©¢æ•´å€‹æ—¥æœŸç¯„åœ

        Args:
            start_date: èµ·å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
        """
        logger.info(
            f"* Start Batch Updating Broker Trading Daily Report: {start_date} to {end_date}"
        )

        # è½‰æ›æ—¥æœŸæ ¼å¼
        if isinstance(start_date, str):
            start_date_obj: datetime.date = datetime.datetime.strptime(
                start_date, "%Y-%m-%d"
            ).date()
        else:
            start_date_obj: datetime.date = start_date

        if isinstance(end_date, str):
            end_date_obj: datetime.date = datetime.datetime.strptime(
                end_date, "%Y-%m-%d"
            ).date()
        else:
            end_date_obj: datetime.date = end_date

        # å–å¾—è¦é–‹å§‹æ›´æ–°çš„æ—¥æœŸï¼ˆå¾è³‡æ–™åº«æœ€æ–°æ—¥æœŸ+1å¤©é–‹å§‹ï¼Œæˆ–ä½¿ç”¨æä¾›çš„ start_dateï¼‰
        actual_start_date: datetime.date = self.get_actual_update_start_date(
            default_date=start_date_obj
        )
        if isinstance(actual_start_date, str):
            actual_start_date = datetime.datetime.strptime(
                actual_start_date, "%Y-%m-%d"
            ).date()

        # å¦‚æœå¯¦éš›é–‹å§‹æ—¥æœŸå·²ç¶“è¶…éçµæŸæ—¥æœŸï¼Œå‰‡ä¸éœ€è¦æ›´æ–°
        if actual_start_date > end_date_obj:
            logger.info(
                f"No new data to update. Latest date in database is already up to date."
            )
            return

        # å–å¾—è‚¡ç¥¨åˆ—è¡¨å’Œåˆ¸å•†åˆ—è¡¨
        stock_list: List[str] = self._get_stock_list()
        trader_list: List[str] = self._get_securities_trader_list()

        if not stock_list:
            logger.warning(
                "No stocks found in database. Please update stock info first."
            )
            return

        if not trader_list:
            logger.warning(
                "No securities traders found in database. Please update broker info first."
            )
            return

        # åˆå§‹åŒ–æ™‚æ›´æ–° metadataï¼ˆå¾è³‡æ–™åº«è®€å–ï¼‰
        logger.info("Initializing broker trading metadata from database...")
        self._update_broker_trading_metadata_from_database()

        total_combinations: int = len(trader_list) * len(stock_list)
        logger.info(
            f"Total update combinations: {len(trader_list)} traders Ã— {len(stock_list)} stocks = {total_combinations}"
        )
        logger.info(
            f"Date range: {actual_start_date.strftime('%Y-%m-%d')} to {end_date_obj.strftime('%Y-%m-%d')}"
        )

        # Loop: åˆ¸å•† -> è‚¡ç¥¨
        combination_count: int = 0
        quota_exhausted: bool = False

        # çµ±è¨ˆå„ç¨®ç‹€æ…‹
        stats: Dict[str, int] = {
            UpdateStatus.SUCCESS.value: 0,
            UpdateStatus.NO_DATA.value: 0,
            UpdateStatus.ALREADY_UP_TO_DATE.value: 0,
            UpdateStatus.ERROR.value: 0,
        }

        # å®šæœŸæ›´æ–° metadata çš„é »ç‡ï¼ˆæ¯è™•ç† N å€‹é …ç›®å¾Œæ›´æ–°ä¸€æ¬¡ï¼‰
        update_metadata_interval: int = 100

        for securities_trader_id in trader_list:
            for stock_id in stock_list:
                # æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆæª¢æŸ¥ metadata ä¸­æ˜¯å¦å·²åŒ…å«æ‰€æœ‰æ—¥æœŸï¼‰
                existing_dates: Set[str] = self._get_existing_dates_from_metadata(
                    securities_trader_id=securities_trader_id,
                    stock_id=stock_id,
                )

                # ç”¢ç”Ÿç›®æ¨™æ—¥æœŸç¯„åœçš„æ‰€æœ‰æ—¥æœŸ
                target_dates: List[datetime.date] = TimeUtils.generate_date_range(
                    actual_start_date, end_date_obj
                )
                target_date_strs: Set[str] = {
                    d.strftime("%Y-%m-%d") for d in target_dates
                }

                # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰æ—¥æœŸéƒ½å·²å­˜åœ¨
                missing_dates: Set[str] = target_date_strs - existing_dates

                if not missing_dates:
                    # æ‰€æœ‰æ—¥æœŸéƒ½å·²å­˜åœ¨ï¼Œè·³éæ­¤çµ„åˆ
                    stats[UpdateStatus.ALREADY_UP_TO_DATE.value] += 1
                    continue

                # åœ¨æ¯æ¬¡ API èª¿ç”¨å‰æª¢æŸ¥ quota
                if not self._check_and_update_api_quota():
                    # è‡ªå‹•ç­‰å¾… quota é‡ç½®ï¼ˆæ¯éš” 10 åˆ†é˜æŸ¥è©¢ä¸€æ¬¡ API usageï¼‰
                    logger.warning(
                        f"âš ï¸ API quota exhausted! Used {self.api_call_count}/{self.api_quota_limit} calls. "
                        f"Progress: {combination_count}/{total_combinations} combinations processed. "
                        f"Last processed: trader={securities_trader_id}, stock={stock_id}"
                    )
                    # æ›´æ–° metadataï¼ˆå¾è³‡æ–™åº«è®€å–ï¼‰
                    logger.info(
                        "Updating broker trading metadata before waiting for quota reset..."
                    )
                    self._update_broker_trading_metadata_from_database()

                    # ç­‰å¾… quota é‡ç½®ï¼ˆæ¯éš” 10 åˆ†é˜æŸ¥è©¢ä¸€æ¬¡ï¼Œæœ€å¤šç­‰å¾… 2 å°æ™‚ï¼‰
                    quota_restored: bool = self._wait_for_quota_reset(
                        check_interval_minutes=10,
                        max_wait_minutes=120,  # æœ€å¤šç­‰å¾… 2 å°æ™‚
                    )

                    if not quota_restored:
                        quota_exhausted = True
                        logger.error(
                            f"âŒ Failed to restore API quota within maximum wait time. "
                            f"Please check API status and restart manually."
                        )
                        break
                    else:
                        # Quota å·²æ¢å¾©ï¼Œç¹¼çºŒè™•ç†
                        logger.info(
                            f"ğŸ”„ Resuming update from trader={securities_trader_id}, stock={stock_id}"
                        )
                        # ä¸ breakï¼Œç¹¼çºŒç•¶å‰å¾ªç’°

                combination_count += 1
                if combination_count % 50 == 0:
                    logger.info(
                        f"Progress: {combination_count}/{total_combinations} combinations processed "
                        f"(API calls: {self.api_call_count}/{self.api_quota_limit}) | "
                        f"Stats: success={stats[UpdateStatus.SUCCESS.value]}, no_data={stats[UpdateStatus.NO_DATA.value]}, "
                        f"error={stats[UpdateStatus.ERROR.value]}, already_up_to_date={stats[UpdateStatus.ALREADY_UP_TO_DATE.value]}"
                    )

                try:
                    # å°å–®ä¸€åˆ¸å•†ã€å–®ä¸€è‚¡ç¥¨ï¼Œä¸€æ¬¡æ€§æŸ¥è©¢æ•´å€‹æ—¥æœŸç¯„åœ
                    # è¨­ç½® skip_processed_check=Trueï¼Œå› ç‚º batch æ–¹æ³•å·²ç¶“æª¢æŸ¥éäº†
                    status: UpdateStatus = self.update_broker_trading_daily_report(
                        stock_id=stock_id,
                        securities_trader_id=securities_trader_id,
                        start_date=actual_start_date,
                        end_date=end_date_obj,
                        skip_processed_check=True,  # é¿å…é‡è¤‡æª¢æŸ¥
                    )

                    if status == UpdateStatus.NO_DATA:
                        logger.debug(
                            f"No data for trader={securities_trader_id}, stock={stock_id} "
                            f"(date range: {actual_start_date} to {end_date_obj})"
                        )

                    # çµ±è¨ˆç‹€æ…‹
                    if status.value in stats:
                        stats[status.value] += 1
                    else:
                        logger.warning(f"Unknown status returned: {status}")
                        stats[UpdateStatus.ERROR.value] += 1

                    # å®šæœŸæ›´æ–° metadataï¼ˆé¿å…ç¨‹å¼æ„å¤–ä¸­æ–·æ™‚éºå¤±é€²åº¦ï¼‰
                    if combination_count % update_metadata_interval == 0:
                        logger.debug(
                            f"Periodically updating metadata at {combination_count} combinations..."
                        )
                        self._update_broker_trading_metadata_from_database()
                except Exception as e:
                    stats[UpdateStatus.ERROR.value] += 1
                    logger.error(
                        f"Error updating broker trading daily report for trader={securities_trader_id}, stock={stock_id}: {e}",
                        exc_info=True,
                    )
                    # ç¹¼çºŒè™•ç†ä¸‹ä¸€å€‹çµ„åˆ
                    continue

            if quota_exhausted:
                break

        # æ›´æ–° metadataï¼ˆç„¡è«–æ˜¯å¦å®Œæˆï¼‰
        logger.info("Updating broker trading metadata after batch update...")
        self._update_broker_trading_metadata_from_database()

        # å¦‚æœ quota ç”¨å®Œï¼Œè¨˜éŒ„ç‹€æ…‹
        if quota_exhausted:
            logger.warning(
                f"âš ï¸ Batch update paused due to API quota exhaustion. "
                f"Processed {combination_count}/{total_combinations} combinations. "
                f"Please wait for quota reset and resume from where it stopped."
            )
        else:
            logger.info(
                f"âœ… Batch update completed. Processed {combination_count} combinations"
            )

        # è¼¸å‡ºè©³ç´°çµ±è¨ˆ
        logger.info(
            f"ğŸ“Š Update Statistics: "
            f"Success={stats[UpdateStatus.SUCCESS.value]}, "
            f"No Data={stats[UpdateStatus.NO_DATA.value]} (API returned empty result), "
            f"Already Up-to-date={stats[UpdateStatus.ALREADY_UP_TO_DATE.value]}, "
            f"Errors={stats[UpdateStatus.ERROR.value]}"
        )

    def update_all(
        self,
        start_date: Optional[Union[datetime.date, str]] = None,
        end_date: Optional[Union[datetime.date, str]] = None,
        stock_id: Optional[str] = None,
        securities_trader_id: Optional[str] = None,
    ) -> None:
        """
        æ›´æ–°æ‰€æœ‰ FinMind è³‡æ–™

        Args:
            start_date: èµ·å§‹æ—¥æœŸï¼ˆåƒ…ç”¨æ–¼ broker_trading_daily_reportï¼‰
            end_date: çµæŸæ—¥æœŸï¼ˆåƒ…ç”¨æ–¼ broker_trading_daily_reportï¼‰
            stock_id: è‚¡ç¥¨ä»£ç¢¼ï¼ˆå¯é¸ï¼Œåƒ…ç”¨æ–¼ broker_trading_daily_reportï¼‰
            securities_trader_id: åˆ¸å•†ä»£ç¢¼ï¼ˆå¯é¸ï¼Œåƒ…ç”¨æ–¼ broker_trading_daily_reportï¼‰
        """

        logger.info("* Start Updating All FinMind Data...")

        # æ›´æ–°å°è‚¡ç¸½è¦½
        self.update_stock_info_with_warrant()

        # æ›´æ–°è­‰åˆ¸å•†è³‡è¨Š
        self.update_broker_info()

        # æ›´æ–°åˆ¸å•†åˆ†é»çµ±è¨ˆï¼ˆéœ€è¦æ—¥æœŸç¯„åœï¼‰
        if start_date is None:
            # é è¨­å¾ 2013/1/1 é–‹å§‹
            start_date = datetime.date(2021, 6, 30)
        if end_date is None:
            end_date = datetime.date.today()

        self.update_broker_trading_daily_report(
            start_date=start_date,
            end_date=end_date,
            stock_id=stock_id,
            securities_trader_id=securities_trader_id,
        )

        logger.info("âœ… All FinMind Data updated successfully")

    def _check_and_update_api_quota(self) -> bool:
        """
        æª¢æŸ¥ API quota æ˜¯å¦è¶³å¤ ï¼Œä¸¦æ›´æ–°èª¿ç”¨æ¬¡æ•¸

        Returns:
            bool: True è¡¨ç¤º quota è¶³å¤ å¯ä»¥ç¹¼çºŒèª¿ç”¨ï¼ŒFalse è¡¨ç¤º quota å·²ç”¨ç›¡
        """
        current_time: float = time.time()

        # å¦‚æœå·²ç¶“è¶…éé‡ç½®æ™‚é–“ï¼Œé‡ç½®è¨ˆæ•¸å™¨
        if current_time >= self.quota_reset_time:
            logger.info(
                f"API quota reset. Previous hour used {self.api_call_count}/{self.api_quota_limit} calls"
            )
            self.api_call_count = 0
            self.quota_reset_time = current_time + 3600  # é‡ç½®ç‚ºä¸‹ä¸€å€‹å°æ™‚

        # æª¢æŸ¥æ˜¯å¦æ¥è¿‘æˆ–è¶…é quota é™åˆ¶ï¼ˆä¿ç•™ 50 æ¬¡ä½œç‚ºç·©è¡ï¼‰
        remaining_quota: int = self.api_quota_limit - self.api_call_count
        if remaining_quota <= 50:
            wait_seconds: int = int(self.quota_reset_time - current_time) + 1
            logger.warning(
                f"âš ï¸ API quota nearly exhausted! Used {self.api_call_count}/{self.api_quota_limit} calls. "
                f"Remaining: {remaining_quota} calls. "
                f"Quota will reset in {wait_seconds} seconds ({wait_seconds // 60} minutes). "
                f"Stopping update to avoid quota exhaustion."
            )
            return False

        # å¢åŠ èª¿ç”¨æ¬¡æ•¸
        self.api_call_count += 1

        # æ¯ 1000 æ¬¡èª¿ç”¨è¨˜éŒ„ä¸€æ¬¡ç‹€æ…‹
        if self.api_call_count % 1000 == 0:
            remaining_quota = self.api_quota_limit - self.api_call_count
            logger.info(
                f"API quota status: {self.api_call_count}/{self.api_quota_limit} calls used, "
                f"{remaining_quota} remaining"
            )

        return True

    def _get_api_remaining_quota_from_api(self) -> Optional[int]:
        """
        å¾ FinMind API æŸ¥è©¢å‰©é¤˜çš„ API quotaï¼ˆå¦‚æœ API æ”¯æ´ï¼‰

        Returns:
            Optional[int]: å‰©é¤˜çš„ API èª¿ç”¨æ¬¡æ•¸ï¼Œå¦‚æœç„¡æ³•æŸ¥è©¢å‰‡è¿”å› None
        """
        try:
            if not self.crawler.api:
                return None

            api = self.crawler.api

            # FinMind API: api.api_usage_limit å›å‚³å‰©é¤˜æ¬¡æ•¸
            if hasattr(api, "api_usage_limit"):
                remaining = api.api_usage_limit
                if isinstance(remaining, int) and remaining >= 0:
                    return remaining

        except Exception as e:
            logger.debug(f"Could not query API remaining quota from FinMind API: {e}")
        return None

    def _wait_for_quota_reset(
        self,
        check_interval_minutes: int = 10,
        max_wait_minutes: Optional[int] = None,
    ) -> bool:
        """
        ç­‰å¾… API quota é‡ç½®ï¼Œæ¯éš”æŒ‡å®šæ™‚é–“æŸ¥è©¢ä¸€æ¬¡ API usage

        Args:
            check_interval_minutes: æ¯éš”å¹¾åˆ†é˜æŸ¥è©¢ä¸€æ¬¡ API usageï¼ˆé è¨­ 10 åˆ†é˜ï¼‰
            max_wait_minutes: æœ€å¤§ç­‰å¾…æ™‚é–“ï¼ˆåˆ†é˜ï¼‰ï¼Œå¦‚æœç‚º None å‰‡ä¸é™åˆ¶

        Returns:
            bool: True è¡¨ç¤º quota å·²æ¢å¾©ï¼ŒFalse è¡¨ç¤ºé”åˆ°æœ€å¤§ç­‰å¾…æ™‚é–“æˆ–ç™¼ç”ŸéŒ¯èª¤
        """
        check_interval_seconds: int = check_interval_minutes * 60
        max_wait_seconds: Optional[int] = (
            max_wait_minutes * 60 if max_wait_minutes else None
        )
        start_wait_time: float = time.time()

        logger.info(
            f"â³ Waiting for API quota reset. Checking every {check_interval_minutes} minutes..."
        )

        while True:
            # æª¢æŸ¥æ˜¯å¦è¶…éæœ€å¤§ç­‰å¾…æ™‚é–“
            if max_wait_seconds:
                elapsed: float = time.time() - start_wait_time
                if elapsed >= max_wait_seconds:
                    logger.warning(
                        f"âš ï¸ Maximum wait time ({max_wait_minutes} minutes) reached. Stopping wait."
                    )
                    return False

            # å˜—è©¦å¾ API æŸ¥è©¢å‰©é¤˜ quota
            remaining: Optional[int] = self._get_api_remaining_quota_from_api()

            if remaining is not None:
                # å¦‚æœèƒ½å¤ æŸ¥è©¢åˆ°å‰©é¤˜ quotaï¼Œæª¢æŸ¥æ˜¯å¦å·²é‡ç½®
                current_usage: int = self.api_quota_limit - remaining
                logger.info(
                    f"ğŸ“Š Current API usage: {current_usage}/{self.api_quota_limit} calls. "
                    f"Remaining: {remaining} calls."
                )

                if remaining > 50:  # æœ‰è¶³å¤ çš„ quotaï¼ˆä¿ç•™ 50 æ¬¡ç·©è¡ï¼‰
                    # é‡ç½®æœ¬åœ°è¨ˆæ•¸å™¨
                    self.api_call_count = 0
                    self.quota_reset_time = time.time() + 3600
                    logger.info(
                        f"âœ… API quota has been reset! Resuming update. "
                        f"Remaining quota: {remaining} calls."
                    )
                    return True
            else:
                # å¦‚æœç„¡æ³•æŸ¥è©¢ API usageï¼Œä½¿ç”¨æ™‚é–“åˆ¤æ–·
                current_time: float = time.time()
                if current_time >= self.quota_reset_time:
                    # å·²ç¶“è¶…éé‡ç½®æ™‚é–“ï¼Œé‡ç½®è¨ˆæ•¸å™¨
                    self.api_call_count = 0
                    self.quota_reset_time = current_time + 3600
                    logger.info(f"âœ… API quota reset time reached. Resuming update.")
                    return True

            # è¨ˆç®—å·²ç­‰å¾…æ™‚é–“
            elapsed: float = time.time() - start_wait_time

            logger.info(
                f"â³ Quota not yet reset. Next check in {check_interval_minutes} minutes. "
                f"(Elapsed: {elapsed / 60:.1f} minutes)"
            )

            # ç­‰å¾…æŒ‡å®šæ™‚é–“
            time.sleep(check_interval_seconds)

    def get_actual_update_start_date(
        self,
        default_date: Union[datetime.date, str],
    ) -> Union[datetime.date, str]:
        """
        å–å¾—å¯¦éš›çš„æ›´æ–°èµ·å§‹æ—¥æœŸï¼ˆè³‡æ–™åº«æœ€æ–°æ—¥æœŸ+1å¤©ï¼Œæˆ–ä½¿ç”¨ default_dateï¼‰

        Args:
            default_date: é è¨­èµ·å§‹æ—¥æœŸï¼ˆåŒæ™‚ç”¨æ–¼æ±ºå®šè¿”å›å€¼çš„é¡å‹ï¼‰

        Returns:
            å¯¦éš›çš„èµ·å§‹æ—¥æœŸï¼Œé¡å‹èˆ‡ default_date ç›¸åŒ
        """

        latest_date: Optional[str] = SQLiteUtils.get_table_latest_value(
            conn=self.conn,
            table_name=STOCK_TRADING_DAILY_REPORT_TABLE_NAME,
            col_name="date",
        )

        if latest_date is not None:
            # å°‡è³‡æ–™åº«ä¸­çš„æ—¥æœŸå­—ä¸²è½‰æ›ç‚º datetime.date
            table_latest_date: datetime.date = datetime.datetime.strptime(
                latest_date, "%Y-%m-%d"
            ).date()

            # åŠ ä¸€å¤©ä½œç‚ºæ–°çš„èµ·å§‹æ—¥æœŸ
            next_date: datetime.date = table_latest_date + datetime.timedelta(days=1)

            # æ ¹æ“š default_date çš„é¡å‹æ±ºå®šè¿”å›æ ¼å¼
            if isinstance(default_date, str):
                return next_date.strftime("%Y-%m-%d")
            else:
                return next_date
        else:
            # å¦‚æœè³‡æ–™åº«ä¸­æ²’æœ‰è³‡æ–™ï¼Œä½¿ç”¨ default_date
            return default_date

    def _get_stock_list(self) -> List[str]:
        """
        å¾è³‡æ–™åº«å–å¾—æ‰€æœ‰è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨

        Returns:
            List[str]: è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨
        """
        try:
            query: str = (
                f"SELECT DISTINCT stock_id FROM {STOCK_INFO_WITH_WARRANT_TABLE_NAME} ORDER BY stock_id"
            )
            df: pd.DataFrame = pd.read_sql_query(query, self.conn)
            stock_list: List[str] = df["stock_id"].astype(str).tolist()
            logger.info(f"Retrieved {len(stock_list)} stocks from database")
            return stock_list
        except Exception as e:
            logger.error(f"Error retrieving stock list: {e}")
            return []

    def _get_securities_trader_list(self) -> List[str]:
        """
        å¾è³‡æ–™åº«å–å¾—æ‰€æœ‰åˆ¸å•†ä»£ç¢¼åˆ—è¡¨

        Returns:
            List[str]: åˆ¸å•†ä»£ç¢¼åˆ—è¡¨
        """
        try:
            query: str = (
                f"SELECT DISTINCT securities_trader_id FROM {SECURITIES_TRADER_INFO_TABLE_NAME} ORDER BY securities_trader_id"
            )
            df: pd.DataFrame = pd.read_sql_query(query, self.conn)
            trader_list: List[str] = df["securities_trader_id"].astype(str).tolist()
            logger.info(
                f"Retrieved {len(trader_list)} securities traders from database"
            )
            return trader_list
        except Exception as e:
            logger.error(f"Error retrieving securities trader list: {e}")
            return []

    def _load_broker_trading_metadata(self) -> Dict[str, Dict[str, Dict[str, str]]]:
        """
        å¾ metadata æ–‡ä»¶è®€å– broker trading çš„æ—¥æœŸç¯„åœè³‡è¨Š

        Returns:
            Dict[str, Dict[str, Dict[str, str]]]: metadata çµæ§‹
                {
                    "broker_id": {
                        "stock_id": {
                            "earliest_date": "2021-01-01",
                            "latest_date": "2023-12-31"
                        }
                    }
                }
        """
        if not self.broker_trading_metadata_path.exists():
            return {}

        try:
            with open(self.broker_trading_metadata_path, "r", encoding="utf-8") as f:
                metadata: Dict[str, Dict[str, Dict[str, str]]] = json.load(f)
                return metadata
        except Exception as e:
            logger.warning(f"Error reading broker trading metadata: {e}")
            return {}

    def _update_broker_trading_metadata_from_database(self) -> None:
        """
        å¾è³‡æ–™åº«è®€å–æ•¸æ“šä¸¦æ›´æ–° broker_trading_metadata.json
        è¨˜éŒ„æ¯å€‹ (broker_id, stock_id) çµ„åˆçš„ earliest_date å’Œ latest_date

        æ­¤æ–¹æ³•å¾è³‡æ–™åº«çš„å¯¦éš›æ•¸æ“šä¾†æ›´æ–° metadataï¼Œä¸ä¾è³´ CSV æª”æ¡ˆ
        """
        metadata: Dict[str, Dict[str, Dict[str, str]]] = (
            self._load_broker_trading_metadata()
        )

        # ç¢ºä¿è³‡æ–™åº«é€£æ¥å­˜åœ¨
        if self.conn is None:
            logger.error("Database connection is not available")
            return

        updated_count: int = 0
        try:
            # å¾è³‡æ–™åº«æŸ¥è©¢æ¯å€‹ (securities_trader_id, stock_id) çµ„åˆçš„æ—¥æœŸç¯„åœ
            query: str = f"""
            SELECT 
                securities_trader_id,
                stock_id,
                MIN(date) as earliest_date,
                MAX(date) as latest_date
            FROM {STOCK_TRADING_DAILY_REPORT_TABLE_NAME}
            GROUP BY securities_trader_id, stock_id
            ORDER BY securities_trader_id, stock_id
            """

            df: pd.DataFrame = pd.read_sql_query(query, self.conn)

            if df.empty:
                logger.info("No broker trading data found in database")
                # å¦‚æœè³‡æ–™åº«æ²’æœ‰è³‡æ–™ï¼Œæ¸…ç©ºæ‰€æœ‰ metadata
                metadata = {}
            else:
                # å»ºç«‹ä¸€å€‹é›†åˆä¾†è¨˜éŒ„è³‡æ–™åº«ä¸­å¯¦éš›å­˜åœ¨çš„çµ„åˆ
                existing_combinations: Set[Tuple[str, str]] = set()

                for _, row in df.iterrows():
                    securities_trader_id: str = str(row["securities_trader_id"])
                    stock_id: str = str(row["stock_id"])
                    earliest_date_str: str = str(row["earliest_date"])
                    latest_date_str: str = str(row["latest_date"])

                    existing_combinations.add((securities_trader_id, stock_id))

                    try:
                        # è§£ææ—¥æœŸ
                        earliest_date: datetime.date = datetime.datetime.strptime(
                            earliest_date_str, "%Y-%m-%d"
                        ).date()
                        latest_date: datetime.date = datetime.datetime.strptime(
                            latest_date_str, "%Y-%m-%d"
                        ).date()

                        # åˆå§‹åŒ– broker_id å¦‚æœä¸å­˜åœ¨
                        if securities_trader_id not in metadata:
                            metadata[securities_trader_id] = {}

                        # æ›´æ–° metadata
                        if stock_id not in metadata[securities_trader_id]:
                            # æ–°é …ç›®ï¼Œç›´æ¥è¨­ç½®æ—¥æœŸç¯„åœ
                            metadata[securities_trader_id][stock_id] = {
                                "earliest_date": earliest_date.strftime("%Y-%m-%d"),
                                "latest_date": latest_date.strftime("%Y-%m-%d"),
                            }
                            updated_count += 1
                        else:
                            # å¦‚æœå·²å­˜åœ¨ï¼Œæ¯”è¼ƒä¸¦æ›´æ–°æ—¥æœŸç¯„åœ
                            existing_earliest: Optional[datetime.date] = None
                            existing_latest: Optional[datetime.date] = None

                            if (
                                "earliest_date"
                                in metadata[securities_trader_id][stock_id]
                            ):
                                existing_earliest = datetime.datetime.strptime(
                                    metadata[securities_trader_id][stock_id][
                                        "earliest_date"
                                    ],
                                    "%Y-%m-%d",
                                ).date()
                            if (
                                "latest_date"
                                in metadata[securities_trader_id][stock_id]
                            ):
                                existing_latest = datetime.datetime.strptime(
                                    metadata[securities_trader_id][stock_id][
                                        "latest_date"
                                    ],
                                    "%Y-%m-%d",
                                ).date()

                            # æ›´æ–°æœ€æ—©æ—¥æœŸ
                            if (
                                existing_earliest is None
                                or earliest_date < existing_earliest
                            ):
                                metadata[securities_trader_id][stock_id][
                                    "earliest_date"
                                ] = earliest_date.strftime("%Y-%m-%d")
                                updated_count += 1

                            # æ›´æ–°æœ€æ™šæ—¥æœŸ
                            if existing_latest is None or latest_date > existing_latest:
                                metadata[securities_trader_id][stock_id][
                                    "latest_date"
                                ] = latest_date.strftime("%Y-%m-%d")
                                updated_count += 1

                    except (ValueError, KeyError) as e:
                        logger.debug(
                            f"Error processing metadata for {securities_trader_id}/{stock_id}: {e}"
                        )
                        continue

                # æ¸…ç† metadata ä¸­è³‡æ–™åº«ä¸å­˜åœ¨çš„è¨˜éŒ„
                removed_count: int = 0
                brokers_to_remove: List[str] = []

                for broker_id, stocks in metadata.items():
                    stocks_to_remove: List[str] = []

                    for stock_id in stocks.keys():
                        if (broker_id, stock_id) not in existing_combinations:
                            # è³‡æ–™åº«ä¸­ä¸å­˜åœ¨æ­¤çµ„åˆï¼Œç§»é™¤ metadata ä¸­çš„è¨˜éŒ„
                            stocks_to_remove.append(stock_id)
                            removed_count += 1

                    # ç§»é™¤ä¸å­˜åœ¨çš„ stock_id
                    for stock_id in stocks_to_remove:
                        del metadata[broker_id][stock_id]

                    # å¦‚æœè©² broker ä¸‹æ²’æœ‰ä»»ä½• stockï¼Œæ¨™è¨˜ç‚ºå¾…ç§»é™¤
                    if not metadata[broker_id]:
                        brokers_to_remove.append(broker_id)

                # ç§»é™¤ç©ºçš„ broker
                for broker_id in brokers_to_remove:
                    del metadata[broker_id]

                if removed_count > 0:
                    logger.info(
                        f"ğŸ§¹ Cleaned {removed_count} metadata entries for non-existent database records"
                    )

                if updated_count > 0:
                    logger.info(
                        f"âœ… Updated broker trading metadata: {updated_count} entries updated from database"
                    )

        except Exception as e:
            logger.error(
                f"Error updating broker trading metadata from database: {e}",
                exc_info=True,
            )

        # ä¿å­˜ metadata
        self.broker_trading_metadata_path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.broker_trading_metadata_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)

    def _check_date_exists_in_metadata(
        self,
        securities_trader_id: str,
        stock_id: str,
        date: Union[datetime.date, str],
    ) -> bool:
        """
        æª¢æŸ¥æŒ‡å®šæ—¥æœŸæ˜¯å¦å·²å­˜åœ¨æ–¼ metadata è¨˜éŒ„çš„æ—¥æœŸç¯„åœå…§

        Args:
            securities_trader_id: åˆ¸å•†ä»£ç¢¼
            stock_id: è‚¡ç¥¨ä»£ç¢¼
            date: è¦æª¢æŸ¥çš„æ—¥æœŸ

        Returns:
            bool: True è¡¨ç¤ºæ—¥æœŸåœ¨ç¯„åœå…§ï¼ŒFalse è¡¨ç¤ºä¸åœ¨ç¯„åœå…§æˆ–æ²’æœ‰è¨˜éŒ„
        """
        # è½‰æ›æ—¥æœŸæ ¼å¼
        if isinstance(date, datetime.date):
            date_obj: datetime.date = date
        else:
            date_obj = datetime.datetime.strptime(str(date), "%Y-%m-%d").date()

        # å¾ metadata è®€å–æ—¥æœŸç¯„åœ
        metadata: Dict[str, Dict[str, Dict[str, str]]] = (
            self._load_broker_trading_metadata()
        )

        if (
            securities_trader_id not in metadata
            or stock_id not in metadata[securities_trader_id]
        ):
            return False

        stock_info: Dict[str, str] = metadata[securities_trader_id][stock_id]

        if "earliest_date" not in stock_info or "latest_date" not in stock_info:
            return False

        try:
            earliest_date: datetime.date = datetime.datetime.strptime(
                stock_info["earliest_date"], "%Y-%m-%d"
            ).date()
            latest_date: datetime.date = datetime.datetime.strptime(
                stock_info["latest_date"], "%Y-%m-%d"
            ).date()

            # æª¢æŸ¥æ—¥æœŸæ˜¯å¦åœ¨ç¯„åœå…§
            return earliest_date <= date_obj <= latest_date
        except (ValueError, KeyError) as e:
            logger.debug(f"Error checking date in metadata: {e}")
            return False

    def _get_existing_dates_from_metadata(
        self,
        securities_trader_id: str,
        stock_id: str,
    ) -> Set[str]:
        """
        å¾ metadata å–å¾—å·²å­˜åœ¨çš„æ—¥æœŸç¯„åœï¼Œä¸¦ç”Ÿæˆæ‰€æœ‰æ—¥æœŸ

        Args:
            securities_trader_id: åˆ¸å•†ä»£ç¢¼
            stock_id: è‚¡ç¥¨ä»£ç¢¼

        Returns:
            Set[str]: å·²å­˜åœ¨çš„æ—¥æœŸé›†åˆï¼ˆæ ¼å¼ç‚º "YYYY-MM-DD"ï¼‰
        """
        # å¾ metadata è®€å–æ—¥æœŸç¯„åœ
        metadata: Dict[str, Dict[str, Dict[str, str]]] = (
            self._load_broker_trading_metadata()
        )

        if (
            securities_trader_id not in metadata
            or stock_id not in metadata[securities_trader_id]
        ):
            return set()

        stock_info: Dict[str, str] = metadata[securities_trader_id][stock_id]

        if "earliest_date" not in stock_info or "latest_date" not in stock_info:
            return set()

        try:
            earliest_date: datetime.date = datetime.datetime.strptime(
                stock_info["earliest_date"], "%Y-%m-%d"
            ).date()
            latest_date: datetime.date = datetime.datetime.strptime(
                stock_info["latest_date"], "%Y-%m-%d"
            ).date()

            # ç”Ÿæˆæ—¥æœŸç¯„åœå…§çš„æ‰€æœ‰æ—¥æœŸ
            date_range: List[datetime.date] = TimeUtils.generate_date_range(
                earliest_date, latest_date
            )
            existing_dates: Set[str] = {d.strftime("%Y-%m-%d") for d in date_range}
            return existing_dates
        except (ValueError, KeyError) as e:
            logger.debug(f"Error getting dates from metadata: {e}")
            return set()
