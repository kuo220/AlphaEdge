import datetime
import sqlite3
import time
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple, Union

import pandas as pd
from FinMind.data import DataLoader
from loguru import logger

from trader.config import (
    BROKER_TRADING_METADATA_PATH,
    DB_PATH,
    SECURITIES_TRADER_INFO_TABLE_NAME,
    STOCK_INFO_TABLE_NAME,
    STOCK_INFO_WITH_WARRANT_TABLE_NAME,
    STOCK_TRADING_DAILY_REPORT_TABLE_NAME,
)
from trader.pipeline.cleaners.finmind_cleaner import FinMindCleaner
from trader.pipeline.crawlers.finmind_crawler import FinMindCrawler
from trader.pipeline.loaders.finmind_loader import FinMindLoader
from trader.pipeline.updaters.base import BaseDataUpdater
from trader.pipeline.utils import FinMindDataType, UpdateStatus
from trader.pipeline.utils.data_utils import DataUtils
from trader.utils import TimeUtils
from trader.utils.instrument import StockUtils
from trader.utils.log_manager import LogManager

"""FinMind data updater: stock info with warrant, broker info, broker trading daily report"""


class FinMindUpdater(BaseDataUpdater):
    """FinMind Updater"""

    def __init__(self):
        super().__init__()

        # SQLite Connection
        self.conn: Optional[sqlite3.Connection] = None

        # ETL
        self.crawler: FinMindCrawler = FinMindCrawler()
        self.cleaner: FinMindCleaner = FinMindCleaner()
        self.loader: FinMindLoader = FinMindLoader()

        # API Quota è¿½è¹¤ï¼ˆåˆå§‹å€¼ï¼Œæœƒåœ¨ setup ä¸­å‹•æ…‹ç²å–ï¼‰
        self.api_quota_limit: int = 20000  # æ¯å°æ™‚æœ€å¤§ API èª¿ç”¨æ¬¡æ•¸ï¼ˆé è¨­å€¼ï¼‰
        self.api_call_count: int = 0  # ç•¶å‰å°æ™‚çš„ API èª¿ç”¨æ¬¡æ•¸
        self.quota_reset_time: float = time.time() + 3600  # ä¸‹æ¬¡é‡ç½®æ™‚é–“ï¼ˆ1å°æ™‚å¾Œï¼‰

        # Broker trading metadata æ–‡ä»¶è·¯å¾‘ï¼ˆè¨˜éŒ„æ¯å€‹ broker_id å’Œ stock_id çš„æ—¥æœŸç¯„åœï¼‰
        self.broker_trading_metadata_path: Path = BROKER_TRADING_METADATA_PATH
        # Metadata å¿«å–ï¼ˆé›™å±¤è¿´åœˆå…§åªè®€å¿«å–ï¼Œæ¸›å°‘é‡è¤‡è®€å– JSONï¼›åƒ…åœ¨ _update_broker_trading_metadata_from_database å¯«å…¥å¾Œæ›´æ–°ï¼‰
        self._metadata_cache: Optional[Dict[str, Dict[str, Dict[str, str]]]] = None

        self.setup()

    def setup(self, *args, **kwargs) -> None:
        """Set Up the Config of Updater"""

        if self.conn is None:
            self.conn: sqlite3.Connection = sqlite3.connect(DB_PATH)
        LogManager.setup_logger("update_finmind.log")

        # å‹•æ…‹ç²å– API quota é™åˆ¶
        try:
            if self.crawler.api and hasattr(self.crawler.api, "api_usage_limit"):
                self.api_quota_limit: int = self.crawler.api.api_usage_limit
                logger.info(
                    f"FinMind API quota limit retrieved: {self.api_quota_limit} calls per hour"
                )
            else:
                logger.warning(
                    f"Could not retrieve API quota limit from FinMind API. Using default: {self.api_quota_limit}"
                )
        except Exception as e:
            logger.warning(
                f"Error retrieving API quota limit: {e}. Using default: {self.api_quota_limit}"
            )

    def update(
        self,
        data_type: Optional[Union[str, FinMindDataType]] = None,
        start_date: Optional[Union[datetime.date, str]] = None,
        end_date: Optional[Union[datetime.date, str]] = None,
        **kwargs,
    ) -> None:
        """
        é€šç”¨æ›´æ–°æ–¹æ³•

        Args:
            data_type: è³‡æ–™é¡å‹ï¼Œå¯é¸å€¼ï¼š
                - FinMindDataType.STOCK_INFO æˆ– "stock_info": æ›´æ–°å°è‚¡ç¸½è¦½ï¼ˆä¸å«æ¬Šè­‰ï¼‰
                - FinMindDataType.STOCK_INFO_WITH_WARRANT æˆ– "stock_info_with_warrant": æ›´æ–°å°è‚¡ç¸½è¦½ï¼ˆå«æ¬Šè­‰ï¼‰
                - FinMindDataType.BROKER_INFO æˆ– "broker_info": æ›´æ–°è­‰åˆ¸å•†è³‡è¨Š
                - FinMindDataType.BROKER_TRADING æˆ– "broker_trading": æ›´æ–°åˆ¸å•†åˆ†é»çµ±è¨ˆ
                - "all" æˆ– None: æ›´æ–°æ‰€æœ‰è³‡æ–™
            start_date: èµ·å§‹æ—¥æœŸï¼ˆåƒ…ç”¨æ–¼ BROKER_TRADINGï¼‰
            end_date: çµæŸæ—¥æœŸï¼ˆåƒ…ç”¨æ–¼ BROKER_TRADINGï¼‰
        """
        # è™•ç† "all" æˆ– None çš„æƒ…æ³
        if data_type is None or (
            isinstance(data_type, str) and data_type.lower() == "all"
        ):
            self.update_all(
                start_date=start_date,
                end_date=end_date,
            )
            return

        # å°‡å­—ä¸²è½‰æ›ç‚º Enumï¼ˆå‘å¾Œå…¼å®¹ï¼‰
        if isinstance(data_type, str):
            data_type_str: str = data_type.upper()
            try:
                data_type = FinMindDataType(data_type_str)
            except ValueError:
                # å˜—è©¦å°å¯«å½¢å¼ï¼ˆæ›´å‹å¥½çš„ç”¨æˆ¶è¼¸å…¥ï¼‰
                data_type_str_lower: str = data_type.lower()
                type_mapping: Dict[str, FinMindDataType] = {
                    dt.value.lower(): dt for dt in FinMindDataType
                }
                if data_type_str_lower in type_mapping:
                    data_type = type_mapping[data_type_str_lower]
                else:
                    raise ValueError(
                        f"Unknown data_type string: {data_type}. "
                        f"Supported strings: {[dt.value.lower() for dt in FinMindDataType]}, 'all'"
                    )

        if data_type == FinMindDataType.STOCK_INFO:
            self.update_stock_info()
        elif data_type == FinMindDataType.STOCK_INFO_WITH_WARRANT:
            self.update_stock_info_with_warrant()
        elif data_type == FinMindDataType.BROKER_INFO:
            self.update_broker_info()
        elif data_type == FinMindDataType.BROKER_TRADING:
            if start_date is None or end_date is None:
                raise ValueError(
                    "start_date and end_date are required for BROKER_TRADING"
                )
            self.update_broker_trading_daily_report(
                start_date=start_date,
                end_date=end_date,
            )
        else:
            raise ValueError(
                f"Unknown data_type: {data_type}. "
                f"Supported types: {[dt.name for dt in FinMindDataType]}, 'all'"
            )

    def update_stock_info(self) -> None:
        """æ›´æ–°å°è‚¡ç¸½è¦½è³‡æ–™ï¼ˆä¸å«æ¬Šè­‰ï¼‰"""

        logger.info("* Start Updating Taiwan Stock Info...")

        # Step 1: Crawl
        df: Optional[pd.DataFrame] = self.crawler.crawl_stock_info()
        if df is None or df.empty:
            logger.warning("No stock info data to update")
            return

        # Step 2: Clean
        cleaned_df: Optional[pd.DataFrame] = self.cleaner.clean_stock_info(df)
        if cleaned_df is None or cleaned_df.empty:
            logger.warning("Cleaned stock info data is empty")
            return

        # Step 3: Load
        # ç¢ºä¿ loader æœ‰é€£æ¥
        if self.loader.conn is None:
            self.loader.connect()
        self.loader.load_stock_info()
        if self.loader.conn:
            self.loader.conn.commit()

        logger.info("âœ… Taiwan Stock Info updated successfully")

    def update_stock_info_with_warrant(self) -> None:
        """æ›´æ–°å°è‚¡ç¸½è¦½(å«æ¬Šè­‰)è³‡æ–™"""

        logger.info("* Start Updating Taiwan Stock Info With Warrant...")

        # Step 1: Crawl
        df: Optional[pd.DataFrame] = self.crawler.crawl_stock_info_with_warrant()
        if df is None or df.empty:
            logger.warning("No stock info with warrant data to update")
            return

        # Step 2: Clean
        cleaned_df: Optional[pd.DataFrame] = self.cleaner.clean_stock_info_with_warrant(
            df
        )
        if cleaned_df is None or cleaned_df.empty:
            logger.warning("Cleaned stock info with warrant data is empty")
            return

        # Step 3: Load
        # ç¢ºä¿ loader æœ‰é€£æ¥
        if self.loader.conn is None:
            self.loader.connect()
        self.loader.load_stock_info_with_warrant()
        if self.loader.conn:
            self.loader.conn.commit()

        logger.info("âœ… Taiwan Stock Info With Warrant updated successfully")

    def update_broker_info(self) -> None:
        """æ›´æ–°è­‰åˆ¸å•†è³‡è¨Šè¡¨è³‡æ–™"""

        logger.info("* Start Updating Broker Info...")

        # Step 1: Crawl
        df: Optional[pd.DataFrame] = self.crawler.crawl_broker_info()
        if df is None or df.empty:
            logger.warning("No broker info data to update")
            return

        # Step 2: Clean
        cleaned_df: Optional[pd.DataFrame] = self.cleaner.clean_broker_info(df)
        if cleaned_df is None or cleaned_df.empty:
            logger.warning("Cleaned broker info data is empty")
            return

        # Step 3: Load
        # ç¢ºä¿ loader æœ‰é€£æ¥
        if self.loader.conn is None:
            self.loader.connect()
        self.loader.load_broker_info()
        if self.loader.conn:
            self.loader.conn.commit()

        logger.info("âœ… Broker Info updated successfully")

    def update_broker_trading_daily_report(
        self,
        start_date: Union[datetime.date, str],
        end_date: Union[datetime.date, str],
    ) -> None:
        """
        æ‰¹é‡æ›´æ–°ç•¶æ—¥åˆ¸å•†åˆ†é»çµ±è¨ˆè¡¨è³‡æ–™

        æ­¤æ–¹æ³•æœƒï¼š
        1. Loop æ‰€æœ‰åˆ¸å•† ID å’Œè‚¡ç¥¨ IDï¼Œæ‰¹é‡æ›´æ–°æ‰€æœ‰çµ„åˆ
        2. å°æ¯å€‹ (åˆ¸å•†, è‚¡ç¥¨) çµ„åˆï¼Œä½¿ç”¨ metadata åˆ¤æ–·éœ€è¦æ›´æ–°çš„æ—¥æœŸç¯„åœ

        Args:
            start_date: èµ·å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
        """
        logger.info(
            f"* Start Updating Broker Trading Daily Report: {start_date} to {end_date}"
        )

        # è½‰æ›æ—¥æœŸæ ¼å¼
        if isinstance(start_date, str):
            start_date_obj: datetime.date = datetime.datetime.strptime(
                start_date, "%Y-%m-%d"
            ).date()
        else:
            start_date_obj: datetime.date = start_date

        if isinstance(end_date, str):
            end_date_obj: datetime.date = datetime.datetime.strptime(
                end_date, "%Y-%m-%d"
            ).date()
        else:
            end_date_obj: datetime.date = end_date

        # å–å¾—è‚¡ç¥¨åˆ—è¡¨å’Œåˆ¸å•†åˆ—è¡¨
        stock_list: List[str] = self._get_stock_list()
        securities_trader_list: List[str] = self._get_securities_trader_list()

        logger.info(
            f"Retrieved stock list: {len(stock_list)} stocks, "
            f"securities trader list: {len(securities_trader_list)} traders"
        )

        if not stock_list:
            logger.warning(
                "No stocks found in database. Please update stock info first."
            )
            return

        # éæ¿¾å‡ºä¸€èˆ¬è‚¡ç¥¨ï¼ˆæ’é™¤ ETFã€æ¬Šè­‰ç­‰ï¼‰
        stock_list: List[str] = StockUtils.filter_common_stocks(stock_list)
        logger.info(
            f"Filtered to {len(stock_list)} common stocks (excluding ETFs, warrants, etc.)"
        )

        if not stock_list:
            logger.warning(
                "No common stocks found after filtering. Please check stock info data."
            )
            return

        if not securities_trader_list:
            logger.warning(
                "No securities traders found in database. Please update broker info first."
            )
            return

        # åˆå§‹åŒ–æ™‚æ›´æ–° metadataï¼ˆå¾è³‡æ–™åº«è®€å–ï¼‰
        logger.info("Initializing broker trading metadata from database...")
        self._update_broker_trading_metadata_from_database()

        total_combinations: int = len(securities_trader_list) * len(stock_list)
        logger.info(
            f"Total update combinations: {len(securities_trader_list)} traders Ã— {len(stock_list)} stocks = {total_combinations}"
        )
        logger.info(
            f"Requested date range: {start_date_obj.strftime('%Y-%m-%d')} to {end_date_obj.strftime('%Y-%m-%d')} "
            f"(each combination will use its own start date based on metadata)"
        )

        # Loop: åˆ¸å•† -> è‚¡ç¥¨
        combination_count: int = 0
        quota_exhausted: bool = False

        # çµ±è¨ˆå„ç¨®ç‹€æ…‹
        stats: Dict[str, int] = {
            UpdateStatus.SUCCESS.value: 0,
            UpdateStatus.NO_DATA.value: 0,
            UpdateStatus.ALREADY_UP_TO_DATE.value: 0,
            UpdateStatus.ERROR.value: 0,
        }

        # å®šæœŸæ›´æ–° metadata çš„é »ç‡ï¼ˆæ¯è™•ç† N å€‹é …ç›®å¾Œæ›´æ–°ä¸€æ¬¡ï¼›éå°å‰‡ I/O é »ç¹ï¼Œéå¤§å‰‡ä¸­æ–·æ™‚å¯èƒ½é‡çˆ¬è¼ƒå¤šï¼‰
        update_metadata_interval: int = 500
        # æ‰¹æ¬¡ commit é »ç‡ï¼ˆæ¯ N å€‹çµ„åˆ commit ä¸€æ¬¡ DBï¼Œæ¸›å°‘ commit æ¬¡æ•¸ï¼›ä¸­æ–·æ™‚æœ€å¤šå°‘æœ€å¾Œæœª commit çš„ä¸€æ‰¹ï¼‰
        commit_interval: int = 50

        # è¼”åŠ©å‡½æ•¸ï¼šè¨˜éŒ„é€²åº¦ä¸¦å®šæœŸæ›´æ–° metadata
        def log_progress_and_update_metadata():
            """è¨˜éŒ„è™•ç†é€²åº¦ä¸¦åœ¨éœ€è¦æ™‚æ›´æ–° metadataï¼ˆé¿å…ç¨‹å¼æ„å¤–ä¸­æ–·æ™‚éºå¤±é€²åº¦ï¼‰"""
            if combination_count % 50 == 0:
                logger.info(
                    f"Progress: {combination_count}/{total_combinations} combinations processed "
                    f"(API calls: {self.api_call_count}/{self.api_quota_limit}) | "
                    f"Stats: success={stats[UpdateStatus.SUCCESS.value]}, no_data={stats[UpdateStatus.NO_DATA.value]}, "
                    f"error={stats[UpdateStatus.ERROR.value]}, already_up_to_date={stats[UpdateStatus.ALREADY_UP_TO_DATE.value]}"
                )
            # å®šæœŸæ›´æ–° metadataï¼ˆé¿å…ç¨‹å¼æ„å¤–ä¸­æ–·æ™‚éºå¤±é€²åº¦ï¼‰
            if combination_count % update_metadata_interval == 0:
                logger.debug(
                    f"Periodically updating metadata at {combination_count} combinations..."
                )
                self._update_broker_trading_metadata_from_database()

        for securities_trader_id in securities_trader_list:
            for stock_id in stock_list:
                # æ¯å€‹çµ„åˆé–‹å§‹è™•ç†æ™‚å°±å¢åŠ è¨ˆæ•¸ï¼ˆç„¡è«–æ˜¯å¦è·³ééƒ½æœƒè¢«è¨ˆå…¥ï¼‰
                combination_count += 1

                # è¨˜éŒ„æ­£åœ¨è™•ç†çš„åˆ¸å•†å’Œè‚¡ç¥¨ï¼ˆæ”¹ç‚º debug æ¸›å°‘ I/Oï¼Œé€²åº¦å·²ç”± log_progress_and_update_metadata æ¯ 50 ç­† log ä¸€æ¬¡ï¼‰
                logger.debug(
                    f"Processing: trader_id={securities_trader_id}, stock_id={stock_id}"
                )

                # ç‚ºæ¯å€‹çµ„åˆæ±ºå®šèµ·å§‹æ—¥æœŸï¼ˆåŸºæ–¼è©²çµ„åˆçš„ metadataï¼Œè€Œéæ•´å€‹è¡¨ï¼‰
                # å¾ metadata å–å¾—è©²çµ„åˆçš„æœ€æ–°æ—¥æœŸ
                metadata: Dict[str, Dict[str, Dict[str, str]]] = (
                    self._load_broker_trading_metadata()
                )

                # æª¢æŸ¥è©²çµ„åˆæ˜¯å¦åœ¨ metadata ä¸­
                combination_in_metadata: bool = (
                    securities_trader_id in metadata
                    and stock_id in metadata[securities_trader_id]
                    and "latest_date" in metadata[securities_trader_id][stock_id]
                )

                combination_start_date: datetime.date = start_date_obj

                if combination_in_metadata:
                    try:
                        # å¦‚æœ metadata ä¸­æœ‰è©²çµ„åˆçš„è³‡æ–™ï¼Œå¾æœ€æ–°æ—¥æœŸ+1é–‹å§‹
                        latest_date_str: str = metadata[securities_trader_id][stock_id][
                            "latest_date"
                        ]
                        latest_date: datetime.date = datetime.datetime.strptime(
                            latest_date_str, "%Y-%m-%d"
                        ).date()
                        combination_start_date = latest_date + datetime.timedelta(
                            days=1
                        )
                    except (ValueError, KeyError) as e:
                        logger.debug(
                            f"Error parsing latest_date from metadata for {securities_trader_id}/{stock_id}: {e}"
                        )
                        combination_start_date = start_date_obj

                # ç¢ºä¿èµ·å§‹æ—¥æœŸä¸æ—©æ–¼ start_date_objï¼Œä¸æ™šæ–¼ end_date_obj
                combination_start_date = max(combination_start_date, start_date_obj)

                # å¦‚æœè©²çµ„åˆä¸åœ¨ metadata ä¸­ï¼Œä¸”èµ·å§‹æ—¥æœŸåœ¨æœ‰æ•ˆç¯„åœå…§ï¼Œæ‡‰è©²è¦æ›´æ–°
                # åªæœ‰åœ¨ metadata ä¸­å­˜åœ¨ä¸”èµ·å§‹æ—¥æœŸè¶…éçµæŸæ—¥æœŸæ™‚æ‰è·³é
                if combination_in_metadata and combination_start_date > end_date_obj:
                    # è©²çµ„åˆå·²ç¶“æ˜¯æœ€æ–°çš„ï¼Œè·³é
                    stats[UpdateStatus.ALREADY_UP_TO_DATE.value] += 1
                    log_progress_and_update_metadata()
                    continue

                # å¦‚æœè©²çµ„åˆä¸åœ¨ metadata ä¸­ï¼Œä½†èµ·å§‹æ—¥æœŸè¶…éçµæŸæ—¥æœŸï¼Œé€™è¡¨ç¤ºæ—¥æœŸç¯„åœç„¡æ•ˆ
                if (
                    not combination_in_metadata
                    and combination_start_date > end_date_obj
                ):
                    logger.warning(
                        f"Invalid date range for new combination {securities_trader_id}/{stock_id}: "
                        f"start_date={combination_start_date} > end_date={end_date_obj}. Skipping."
                    )
                    stats[UpdateStatus.ALREADY_UP_TO_DATE.value] += 1
                    log_progress_and_update_metadata()
                    continue

                # æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆæª¢æŸ¥ metadata ä¸­æ˜¯å¦å·²åŒ…å«æ‰€æœ‰æ—¥æœŸï¼‰
                existing_dates: Set[str] = self._get_existing_dates_from_metadata(
                    securities_trader_id=securities_trader_id,
                    stock_id=stock_id,
                )

                # ç”¢ç”Ÿç›®æ¨™æ—¥æœŸç¯„åœçš„æ‰€æœ‰æ—¥æœŸ
                target_dates: List[datetime.date] = TimeUtils.generate_date_range(
                    combination_start_date, end_date_obj
                )

                # å¦‚æœæ—¥æœŸç¯„åœç‚ºç©ºï¼ˆä¾‹å¦‚ start_date > end_dateï¼‰ï¼Œè·³é
                if not target_dates:
                    logger.warning(
                        f"Empty date range for {securities_trader_id}/{stock_id}: "
                        f"start_date={combination_start_date}, end_date={end_date_obj}. Skipping."
                    )
                    stats[UpdateStatus.ALREADY_UP_TO_DATE.value] += 1
                    log_progress_and_update_metadata()
                    continue

                target_date_strs: Set[str] = {
                    d.strftime("%Y-%m-%d") for d in target_dates
                }

                # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰æ—¥æœŸéƒ½å·²å­˜åœ¨
                missing_dates: Set[str] = target_date_strs - existing_dates

                if not missing_dates:
                    # æ‰€æœ‰æ—¥æœŸéƒ½å·²å­˜åœ¨ï¼Œè·³éæ­¤çµ„åˆ
                    # ä½†å¦‚æœæ˜¯æ–°çµ„åˆï¼ˆä¸åœ¨ metadata ä¸­ï¼‰ï¼Œé€™ä¸æ‡‰è©²ç™¼ç”Ÿï¼Œè¨˜éŒ„è­¦å‘Š
                    if not combination_in_metadata:
                        logger.warning(
                            f"Unexpected: combination {securities_trader_id}/{stock_id} not in metadata "
                            f"but all dates {target_date_strs} appear to exist. This may indicate a logic error."
                        )
                    stats[UpdateStatus.ALREADY_UP_TO_DATE.value] += 1
                    log_progress_and_update_metadata()
                    continue

                # åœ¨æ¯æ¬¡ API èª¿ç”¨å‰æª¢æŸ¥ quota
                if not self._check_and_update_api_quota():
                    # è‡ªå‹•ç­‰å¾… quota é‡ç½®ï¼ˆæ¯éš” 10 åˆ†é˜æŸ¥è©¢ä¸€æ¬¡ API usageï¼‰
                    logger.warning(
                        f"âš ï¸ API quota exhausted! Used {self.api_call_count}/{self.api_quota_limit} calls. "
                        f"Progress: {combination_count}/{total_combinations} combinations processed. "
                        f"Last processed: trader={securities_trader_id}, stock={stock_id}"
                    )
                    # æ›´æ–° metadataï¼ˆå¾è³‡æ–™åº«è®€å–ï¼‰
                    logger.info(
                        "Updating broker trading metadata before waiting for quota reset..."
                    )
                    self._update_broker_trading_metadata_from_database()

                    # ç­‰å¾… quota é‡ç½®ï¼ˆæ¯éš” 10 åˆ†é˜æŸ¥è©¢ä¸€æ¬¡ï¼Œæœ€å¤šç­‰å¾… 2 å°æ™‚ï¼‰
                    quota_restored: bool = self._wait_for_quota_reset(
                        check_interval_minutes=10,
                        max_wait_minutes=120,  # æœ€å¤šç­‰å¾… 2 å°æ™‚
                    )

                    if not quota_restored:
                        quota_exhausted: bool = True
                        logger.error(
                            f"âŒ Failed to restore API quota within maximum wait time. "
                            f"Please check API status and restart manually."
                        )
                        break
                    else:
                        # Quota å·²æ¢å¾©ï¼Œç¹¼çºŒè™•ç†
                        logger.info(
                            f"ğŸ”„ Resuming update from trader={securities_trader_id}, stock={stock_id}"
                        )
                        # ä¸ breakï¼Œç¹¼çºŒç•¶å‰å¾ªç’°

                try:
                    # å°å–®ä¸€åˆ¸å•†ã€å–®ä¸€è‚¡ç¥¨ï¼Œä¸€æ¬¡æ€§æŸ¥è©¢æ•´å€‹æ—¥æœŸç¯„åœï¼ˆæ‰¹æ¬¡æ™‚ä¸åœ¨æ­¤è™• commitï¼Œç”±ä¸‹æ–¹æ¯ N ç­†çµ±ä¸€ commitï¼‰
                    status: UpdateStatus = self._update_broker_trading_daily_report(
                        stock_id=stock_id,
                        securities_trader_id=securities_trader_id,
                        start_date=combination_start_date,
                        end_date=end_date_obj,
                        do_commit=False,
                    )

                    if status == UpdateStatus.NO_DATA:
                        logger.debug(
                            f"No data for trader={securities_trader_id}, stock={stock_id} "
                            f"(date range: {combination_start_date} to {end_date_obj})"
                        )

                    # çµ±è¨ˆç‹€æ…‹
                    if status.value in stats:
                        stats[status.value] += 1
                    else:
                        logger.warning(f"Unknown status returned: {status}")
                        stats[UpdateStatus.ERROR.value] += 1
                except Exception as e:
                    stats[UpdateStatus.ERROR.value] += 1
                    logger.error(
                        f"Error updating broker trading daily report for trader={securities_trader_id}, stock={stock_id}: {e}",
                        exc_info=True,
                    )

                # è™•ç†å®Œæˆå¾Œæª¢æŸ¥æ˜¯å¦éœ€è¦æ‰“å°é€²åº¦ï¼Œä¸¦æ¯ N ç­† commit ä¸€æ¬¡ DB
                log_progress_and_update_metadata()
                if combination_count % commit_interval == 0 and self.loader.conn:
                    self.loader.conn.commit()

            if quota_exhausted:
                break

        # å°‡å°šæœª commit çš„å¯«å…¥ä¸€æ¬¡æäº¤ï¼Œå†æ›´æ–° metadata
        if self.loader.conn:
            self.loader.conn.commit()
        # æ›´æ–° metadataï¼ˆç„¡è«–æ˜¯å¦å®Œæˆï¼‰
        logger.info("Updating broker trading metadata after batch update...")
        self._update_broker_trading_metadata_from_database()

        # å¦‚æœ quota ç”¨å®Œï¼Œè¨˜éŒ„ç‹€æ…‹
        if quota_exhausted:
            logger.warning(
                f"âš ï¸ Batch update paused due to API quota exhaustion. "
                f"Processed {combination_count}/{total_combinations} combinations. "
                f"Please wait for quota reset and resume from where it stopped."
            )
        else:
            logger.info(
                f"âœ… Batch update completed. Processed {combination_count} combinations"
            )

        # è¼¸å‡ºè©³ç´°çµ±è¨ˆ
        logger.info(
            f"ğŸ“Š Update Statistics: "
            f"Success={stats[UpdateStatus.SUCCESS.value]}, "
            f"No Data={stats[UpdateStatus.NO_DATA.value]} (API returned empty result), "
            f"Already Up-to-date={stats[UpdateStatus.ALREADY_UP_TO_DATE.value]}, "
            f"Errors={stats[UpdateStatus.ERROR.value]}"
        )

    def update_all(
        self,
        start_date: Optional[Union[datetime.date, str]] = None,
        end_date: Optional[Union[datetime.date, str]] = None,
    ) -> None:
        """
        æ›´æ–°æ‰€æœ‰ FinMind è³‡æ–™

        Args:
            start_date: èµ·å§‹æ—¥æœŸï¼ˆåƒ…ç”¨æ–¼ broker_trading_daily_reportï¼‰
            end_date: çµæŸæ—¥æœŸï¼ˆåƒ…ç”¨æ–¼ broker_trading_daily_reportï¼‰
        """

        logger.info("* Start Updating All FinMind Data...")

        # æ›´æ–°å°è‚¡ç¸½è¦½ï¼ˆä¸å«æ¬Šè­‰ï¼‰
        self.update_stock_info()

        # æ›´æ–°å°è‚¡ç¸½è¦½ï¼ˆå«æ¬Šè­‰ï¼‰
        self.update_stock_info_with_warrant()

        # æ›´æ–°è­‰åˆ¸å•†è³‡è¨Š
        self.update_broker_info()

        # æ›´æ–°åˆ¸å•†åˆ†é»çµ±è¨ˆï¼ˆéœ€è¦æ—¥æœŸç¯„åœï¼‰
        if start_date is None:
            # é è¨­å¾ 2021/6/30 é–‹å§‹
            start_date: Union[datetime.date, str] = datetime.date(2021, 6, 30)
        if end_date is None:
            end_date: Union[datetime.date, str] = datetime.date.today()

        # æ‰¹é‡æ›´æ–°æ‰€æœ‰åˆ¸å•†å’Œè‚¡ç¥¨çµ„åˆ
        self.update_broker_trading_daily_report(
            start_date=start_date,
            end_date=end_date,
        )

        logger.info("âœ… All FinMind Data updated successfully")

    # ============================================================================
    # Private Methods - Core Update Methods
    # ============================================================================

    def _update_broker_trading_daily_report(
        self,
        stock_id: str,
        securities_trader_id: str,
        start_date: Union[datetime.date, str],
        end_date: Union[datetime.date, str],
        do_commit: bool = True,
    ) -> UpdateStatus:
        """
        æ ¸å¿ƒæ–¹æ³•ï¼šæ›´æ–°åˆ¸å•†åˆ†é»çµ±è¨ˆè¡¨è³‡æ–™ï¼ˆçµ¦å®šè‚¡ç¥¨ã€åˆ¸å•†èˆ‡æ—¥æœŸå€é–“ï¼Œä¸åŒ…å«æ™‚é–“åˆ¤æ–·é‚è¼¯ï¼‰

        Args:
            stock_id: è‚¡ç¥¨ä»£ç¢¼
            securities_trader_id: åˆ¸å•†ä»£ç¢¼
            start_date: èµ·å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            do_commit: æ˜¯å¦åœ¨å¯«å…¥å¾Œç«‹å³ commitï¼›æ‰¹æ¬¡æ›´æ–°æ™‚ç”±å‘¼å«ç«¯å‚³ False ä¸¦å®šæœŸ commit

        Returns:
            UpdateStatus: æ›´æ–°ç‹€æ…‹
                - UpdateStatus.SUCCESS: æˆåŠŸæ›´æ–°
                - UpdateStatus.NO_DATA: æ²’æœ‰è³‡æ–™ï¼ˆAPI è¿”å›ç©ºçµæœï¼‰
                - UpdateStatus.ERROR: ç™¼ç”ŸéŒ¯èª¤
        """
        logger.info(
            f"Crawling and saving broker trading daily report: "
            f"trader={securities_trader_id}, stock={stock_id}, "
            f"date={start_date} to {end_date}"
        )

        try:
            # Step 1: Crawl
            df: Optional[pd.DataFrame] = self.crawler.crawl_broker_trading_daily_report(
                stock_id=stock_id,
                securities_trader_id=securities_trader_id,
                start_date=start_date,
                end_date=end_date,
            )
            if df is None or df.empty:
                logger.debug(
                    f"No broker trading daily report data for stock_id={stock_id}, "
                    f"securities_trader_id={securities_trader_id}, "
                    f"date={start_date} to {end_date}"
                )
                return UpdateStatus.NO_DATA

            # Step 2: Clean
            cleaned_df: Optional[pd.DataFrame] = (
                self.cleaner.clean_broker_trading_daily_report(df)
            )
            if cleaned_df is None or cleaned_df.empty:
                logger.warning("Cleaned broker trading daily report data is empty")
                return UpdateStatus.NO_DATA

            # Step 3: Load - å°‡è³‡æ–™ä¿å­˜åˆ°è³‡æ–™åº«
            # ä½¿ç”¨ loader çš„æ–¹æ³•ä¾†è¼‰å…¥è³‡æ–™ï¼ˆdo_commit=False æ™‚ç”±æ‰¹æ¬¡è¿´åœˆå®šæœŸ commitï¼‰
            saved_count: int = self.loader.load_broker_trading_daily_report(
                df=cleaned_df, commit=do_commit
            )

            if saved_count == 0:
                logger.debug("No new data was saved to database")
                return UpdateStatus.SUCCESS

            # æˆåŠŸå¾Œç”¨ç•¶æ¬¡ DataFrame çš„ date æœ€å¤§å€¼ logï¼Œé¿å…é¡å¤–æŸ¥è©¢ DB
            if "date" in cleaned_df.columns and not cleaned_df.empty:
                latest_date_from_df = str(cleaned_df["date"].max())
                logger.info(
                    f"âœ… Broker trading daily report updated successfully. Latest date in batch: {latest_date_from_df}"
                )
            else:
                logger.info("âœ… Broker trading daily report updated successfully.")
            return UpdateStatus.SUCCESS

        except Exception as e:
            logger.error(
                f"Error updating broker trading daily report: {e}",
                exc_info=True,
            )
            return UpdateStatus.ERROR

    # ============================================================================
    # Private Methods - API Quota Management
    # ============================================================================

    def _check_and_update_api_quota(self) -> bool:
        """
        æª¢æŸ¥ API quota æ˜¯å¦è¶³å¤ ï¼Œä¸¦æ›´æ–°èª¿ç”¨æ¬¡æ•¸

        Returns:
            bool: True è¡¨ç¤º quota è¶³å¤ å¯ä»¥ç¹¼çºŒèª¿ç”¨ï¼ŒFalse è¡¨ç¤º quota å·²ç”¨ç›¡
        """
        current_time: float = time.time()

        # å¦‚æœå·²ç¶“è¶…éé‡ç½®æ™‚é–“ï¼Œé‡ç½®è¨ˆæ•¸å™¨
        if current_time >= self.quota_reset_time:
            logger.info(
                f"API quota reset. Previous hour used {self.api_call_count}/{self.api_quota_limit} calls"
            )
            self.api_call_count: int = 0
            self.quota_reset_time: float = current_time + 3600  # é‡ç½®ç‚ºä¸‹ä¸€å€‹å°æ™‚

        # æª¢æŸ¥æ˜¯å¦æ¥è¿‘æˆ–è¶…é quota é™åˆ¶ï¼ˆä¿ç•™ 50 æ¬¡ä½œç‚ºç·©è¡ï¼‰
        remaining_quota: int = self.api_quota_limit - self.api_call_count
        if remaining_quota <= 50:
            wait_seconds: int = int(self.quota_reset_time - current_time) + 1
            logger.warning(
                f"âš ï¸ API quota nearly exhausted! Used {self.api_call_count}/{self.api_quota_limit} calls. "
                f"Remaining: {remaining_quota} calls. "
                f"Quota will reset in {wait_seconds} seconds ({wait_seconds // 60} minutes). "
                f"Stopping update to avoid quota exhaustion."
            )
            return False

        # å¢åŠ èª¿ç”¨æ¬¡æ•¸
        self.api_call_count += 1

        # æ¯ 1000 æ¬¡èª¿ç”¨è¨˜éŒ„ä¸€æ¬¡ç‹€æ…‹
        if self.api_call_count % 1000 == 0:
            remaining_quota: int = self.api_quota_limit - self.api_call_count
            logger.info(
                f"API quota status: {self.api_call_count}/{self.api_quota_limit} calls used, "
                f"{remaining_quota} remaining"
            )

        return True

    def _get_api_remaining_quota_from_api(self) -> Optional[int]:
        """
        å¾ FinMind API æŸ¥è©¢å‰©é¤˜çš„ API quotaï¼ˆå¦‚æœ API æ”¯æ´ï¼‰

        Returns:
            Optional[int]: å‰©é¤˜çš„ API èª¿ç”¨æ¬¡æ•¸ï¼Œå¦‚æœç„¡æ³•æŸ¥è©¢å‰‡è¿”å› None
        """
        try:
            if not self.crawler.api:
                return None

            api: DataLoader = self.crawler.api

            # FinMind API: api.api_usage_limit å›å‚³å‰©é¤˜æ¬¡æ•¸
            if hasattr(api, "api_usage_limit"):
                remaining: int = api.api_usage_limit
                if isinstance(remaining, int) and remaining >= 0:
                    return remaining

        except Exception as e:
            logger.debug(f"Could not query API remaining quota from FinMind API: {e}")
        return None

    def _wait_for_quota_reset(
        self,
        check_interval_minutes: int = 10,
        max_wait_minutes: Optional[int] = None,
    ) -> bool:
        """
        ç­‰å¾… API quota é‡ç½®ï¼Œæ¯éš”æŒ‡å®šæ™‚é–“æŸ¥è©¢ä¸€æ¬¡ API usage

        Args:
            check_interval_minutes: æ¯éš”å¹¾åˆ†é˜æŸ¥è©¢ä¸€æ¬¡ API usageï¼ˆé è¨­ 10 åˆ†é˜ï¼‰
            max_wait_minutes: æœ€å¤§ç­‰å¾…æ™‚é–“ï¼ˆåˆ†é˜ï¼‰ï¼Œå¦‚æœç‚º None å‰‡ä¸é™åˆ¶

        Returns:
            bool: True è¡¨ç¤º quota å·²æ¢å¾©ï¼ŒFalse è¡¨ç¤ºé”åˆ°æœ€å¤§ç­‰å¾…æ™‚é–“æˆ–ç™¼ç”ŸéŒ¯èª¤
        """
        check_interval_seconds: int = check_interval_minutes * 60
        max_wait_seconds: Optional[int] = (
            max_wait_minutes * 60 if max_wait_minutes else None
        )
        start_wait_time: float = time.time()

        logger.info(
            f"â³ Waiting for API quota reset. Checking every {check_interval_minutes} minutes..."
        )

        while True:
            # æª¢æŸ¥æ˜¯å¦è¶…éæœ€å¤§ç­‰å¾…æ™‚é–“
            if max_wait_seconds:
                elapsed: float = time.time() - start_wait_time
                if elapsed >= max_wait_seconds:
                    logger.warning(
                        f"âš ï¸ Maximum wait time ({max_wait_minutes} minutes) reached. Stopping wait."
                    )
                    return False

            # å˜—è©¦å¾ API æŸ¥è©¢å‰©é¤˜ quota
            remaining: Optional[int] = self._get_api_remaining_quota_from_api()

            if remaining is not None:
                # å¦‚æœèƒ½å¤ æŸ¥è©¢åˆ°å‰©é¤˜ quotaï¼Œæª¢æŸ¥æ˜¯å¦å·²é‡ç½®
                current_usage: int = self.api_quota_limit - remaining
                logger.info(
                    f"ğŸ“Š Current API usage: {current_usage}/{self.api_quota_limit} calls. "
                    f"Remaining: {remaining} calls."
                )

                if remaining > 50:  # æœ‰è¶³å¤ çš„ quotaï¼ˆä¿ç•™ 50 æ¬¡ç·©è¡ï¼‰
                    # é‡ç½®æœ¬åœ°è¨ˆæ•¸å™¨
                    self.api_call_count: int = 0
                    self.quota_reset_time: float = time.time() + 3600
                    logger.info(
                        f"âœ… API quota has been reset! Resuming update. "
                        f"Remaining quota: {remaining} calls."
                    )
                    return True
            else:
                # å¦‚æœç„¡æ³•æŸ¥è©¢ API usageï¼Œä½¿ç”¨æ™‚é–“åˆ¤æ–·
                current_time: float = time.time()
                if current_time >= self.quota_reset_time:
                    # å·²ç¶“è¶…éé‡ç½®æ™‚é–“ï¼Œé‡ç½®è¨ˆæ•¸å™¨
                    self.api_call_count: int = 0
                    self.quota_reset_time: float = current_time + 3600
                    logger.info(f"âœ… API quota reset time reached. Resuming update.")
                    return True

            # è¨ˆç®—å·²ç­‰å¾…æ™‚é–“
            elapsed: float = time.time() - start_wait_time

            logger.info(
                f"â³ Quota not yet reset. Next check in {check_interval_minutes} minutes. "
                f"(Elapsed: {elapsed / 60:.1f} minutes)"
            )

            # ç­‰å¾…æŒ‡å®šæ™‚é–“
            time.sleep(check_interval_seconds)

    # ============================================================================
    # Private Methods - Data Retrieval
    # ============================================================================

    def _get_stock_list(self) -> List[str]:
        """
        å¾è³‡æ–™åº«å–å¾—æ‰€æœ‰è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨ï¼ˆä½¿ç”¨ stock_infoï¼Œä¸å«æ¬Šè­‰ï¼‰

        Returns:
            List[str]: è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨
        """
        try:
            query: str = (
                f"SELECT DISTINCT stock_id FROM {STOCK_INFO_TABLE_NAME} ORDER BY stock_id"
            )
            df: pd.DataFrame = pd.read_sql_query(query, self.conn)
            stock_list: List[str] = df["stock_id"].astype(str).tolist()
            logger.info(f"Retrieved {len(stock_list)} stocks from database")
            return stock_list
        except Exception as e:
            logger.error(f"Error retrieving stock list: {e}")
            return []

    def _get_securities_trader_list(self) -> List[str]:
        """
        å¾è³‡æ–™åº«å–å¾—æ‰€æœ‰åˆ¸å•†ä»£ç¢¼åˆ—è¡¨

        Returns:
            List[str]: åˆ¸å•†ä»£ç¢¼åˆ—è¡¨
        """
        try:
            query: str = (
                f"SELECT DISTINCT securities_trader_id FROM {SECURITIES_TRADER_INFO_TABLE_NAME} ORDER BY securities_trader_id"
            )
            df: pd.DataFrame = pd.read_sql_query(query, self.conn)
            securities_trader_list: List[str] = (
                df["securities_trader_id"].astype(str).tolist()
            )
            logger.info(
                f"Retrieved {len(securities_trader_list)} securities traders from database"
            )
            return securities_trader_list
        except Exception as e:
            logger.error(f"Error retrieving securities trader list: {e}")
            return []

    # ============================================================================
    # Private Methods - Metadata Management
    # ============================================================================

    def _load_broker_trading_metadata(self) -> Dict[str, Dict[str, Dict[str, str]]]:
        """
        å¾ metadata æ–‡ä»¶è®€å– broker trading çš„æ—¥æœŸç¯„åœè³‡è¨Šã€‚
        è‹¥æœ‰å¿«å–ï¼ˆ_metadata_cacheï¼‰å‰‡ç›´æ¥å›å‚³ï¼Œæ¸›å°‘é‡è¤‡ I/Oï¼›å¿«å–åƒ…åœ¨
        _update_broker_trading_metadata_from_database æˆåŠŸå¯«å…¥å¾Œæ›´æ–°ã€‚

        Returns:
            Dict[str, Dict[str, Dict[str, str]]]: metadata çµæ§‹
                {
                    "broker_id": {
                        "stock_id": {
                            "earliest_date": "2021-01-01",
                            "latest_date": "2023-12-31"
                        }
                    }
                }
        """
        if self._metadata_cache is not None:
            return self._metadata_cache

        if not self.broker_trading_metadata_path.exists():
            return {}

        try:
            metadata: Dict[str, Dict[str, Dict[str, str]]] = DataUtils.load_json(
                self.broker_trading_metadata_path
            )
            return metadata if metadata is not None else {}
        except Exception as e:
            logger.warning(f"Error reading broker trading metadata: {e}")
            return {}

    def _update_broker_trading_metadata_from_database(self) -> None:
        """
        å¾è³‡æ–™åº«è®€å–æ•¸æ“šä¸¦æ›´æ–° broker_trading_metadata.json
        è¨˜éŒ„æ¯å€‹ (broker_id, stock_id) çµ„åˆçš„ earliest_date å’Œ latest_date

        æ­¤æ–¹æ³•å¾è³‡æ–™åº«çš„å¯¦éš›æ•¸æ“šä¾†æ›´æ–° metadataï¼Œä¸ä¾è³´ CSV æª”æ¡ˆ
        """
        metadata: Dict[str, Dict[str, Dict[str, str]]] = (
            self._load_broker_trading_metadata()
        )

        # ç¢ºä¿è³‡æ–™åº«é€£æ¥å­˜åœ¨
        if self.conn is None:
            logger.error("Database connection is not available")
            return

        updated_count: int = 0
        try:
            # å¾è³‡æ–™åº«æŸ¥è©¢æ¯å€‹ (securities_trader_id, stock_id) çµ„åˆçš„æ—¥æœŸç¯„åœ
            query: str = f"""
            SELECT 
                securities_trader_id,
                stock_id,
                MIN(date) as earliest_date,
                MAX(date) as latest_date
            FROM {STOCK_TRADING_DAILY_REPORT_TABLE_NAME}
            GROUP BY securities_trader_id, stock_id
            ORDER BY securities_trader_id, stock_id
            """

            df: pd.DataFrame = pd.read_sql_query(query, self.conn)

            if df.empty:
                logger.info("No broker trading data found in database")
                # å¦‚æœè³‡æ–™åº«æ²’æœ‰è³‡æ–™ï¼Œæ¸…ç©ºæ‰€æœ‰ metadata
                metadata = {}
            else:
                # å»ºç«‹ä¸€å€‹é›†åˆä¾†è¨˜éŒ„è³‡æ–™åº«ä¸­å¯¦éš›å­˜åœ¨çš„çµ„åˆ
                existing_combinations: Set[Tuple[str, str]] = set()

                for _, row in df.iterrows():
                    securities_trader_id: str = str(row["securities_trader_id"])
                    stock_id: str = str(row["stock_id"])
                    earliest_date_str: str = str(row["earliest_date"])
                    latest_date_str: str = str(row["latest_date"])

                    existing_combinations.add((securities_trader_id, stock_id))

                    try:
                        # è§£ææ—¥æœŸ
                        earliest_date: datetime.date = datetime.datetime.strptime(
                            earliest_date_str, "%Y-%m-%d"
                        ).date()
                        latest_date: datetime.date = datetime.datetime.strptime(
                            latest_date_str, "%Y-%m-%d"
                        ).date()

                        # åˆå§‹åŒ– broker_id å¦‚æœä¸å­˜åœ¨
                        if securities_trader_id not in metadata:
                            metadata[securities_trader_id] = {}

                        # æ›´æ–° metadata
                        if stock_id not in metadata[securities_trader_id]:
                            # æ–°é …ç›®ï¼Œç›´æ¥è¨­ç½®æ—¥æœŸç¯„åœ
                            metadata[securities_trader_id][stock_id] = {
                                "earliest_date": earliest_date.strftime("%Y-%m-%d"),
                                "latest_date": latest_date.strftime("%Y-%m-%d"),
                            }
                            updated_count += 1
                        else:
                            # å¦‚æœå·²å­˜åœ¨ï¼Œæ¯”è¼ƒä¸¦æ›´æ–°æ—¥æœŸç¯„åœ
                            existing_earliest: Optional[datetime.date] = None
                            existing_latest: Optional[datetime.date] = None

                            if (
                                "earliest_date"
                                in metadata[securities_trader_id][stock_id]
                            ):
                                existing_earliest = datetime.datetime.strptime(
                                    metadata[securities_trader_id][stock_id][
                                        "earliest_date"
                                    ],
                                    "%Y-%m-%d",
                                ).date()
                            if (
                                "latest_date"
                                in metadata[securities_trader_id][stock_id]
                            ):
                                existing_latest = datetime.datetime.strptime(
                                    metadata[securities_trader_id][stock_id][
                                        "latest_date"
                                    ],
                                    "%Y-%m-%d",
                                ).date()

                            # æ›´æ–°æœ€æ—©æ—¥æœŸ
                            if (
                                existing_earliest is None
                                or earliest_date < existing_earliest
                            ):
                                metadata[securities_trader_id][stock_id][
                                    "earliest_date"
                                ] = earliest_date.strftime("%Y-%m-%d")
                                updated_count += 1

                            # æ›´æ–°æœ€æ™šæ—¥æœŸ
                            if existing_latest is None or latest_date > existing_latest:
                                metadata[securities_trader_id][stock_id][
                                    "latest_date"
                                ] = latest_date.strftime("%Y-%m-%d")
                                updated_count += 1

                    except (ValueError, KeyError) as e:
                        logger.debug(
                            f"Error processing metadata for {securities_trader_id}/{stock_id}: {e}"
                        )
                        continue

                # æ¸…ç† metadata ä¸­è³‡æ–™åº«ä¸å­˜åœ¨çš„è¨˜éŒ„
                removed_count: int = 0
                brokers_to_remove: List[str] = []

                for broker_id, stocks in metadata.items():
                    stocks_to_remove: List[str] = []

                    for stock_id in stocks.keys():
                        if (broker_id, stock_id) not in existing_combinations:
                            # è³‡æ–™åº«ä¸­ä¸å­˜åœ¨æ­¤çµ„åˆï¼Œç§»é™¤ metadata ä¸­çš„è¨˜éŒ„
                            stocks_to_remove.append(stock_id)
                            removed_count += 1

                    # ç§»é™¤ä¸å­˜åœ¨çš„ stock_id
                    for stock_id in stocks_to_remove:
                        del metadata[broker_id][stock_id]

                    # å¦‚æœè©² broker ä¸‹æ²’æœ‰ä»»ä½• stockï¼Œæ¨™è¨˜ç‚ºå¾…ç§»é™¤
                    if not metadata[broker_id]:
                        brokers_to_remove.append(broker_id)

                # ç§»é™¤ç©ºçš„ broker
                for broker_id in brokers_to_remove:
                    del metadata[broker_id]

                if removed_count > 0:
                    logger.info(
                        f"ğŸ§¹ Cleaned {removed_count} metadata entries for non-existent database records"
                    )

                if updated_count > 0:
                    logger.info(
                        f"âœ… Updated broker trading metadata: {updated_count} entries updated from database"
                    )

        except Exception as e:
            logger.error(
                f"Error updating broker trading metadata from database: {e}",
                exc_info=True,
            )

        # ä¿å­˜ metadata
        DataUtils.save_json(
            metadata,
            self.broker_trading_metadata_path,
            indent=2,
            ensure_ascii=False,
        )
        # å¯«å…¥æˆåŠŸå¾Œæ›´æ–°å¿«å–ï¼Œè¿´åœˆå…§å¾ŒçºŒ _load åªè®€å¿«å–
        self._metadata_cache = metadata

    def _check_date_exists_in_metadata(
        self,
        securities_trader_id: str,
        stock_id: str,
        date: Union[datetime.date, str],
    ) -> bool:
        """
        æª¢æŸ¥æŒ‡å®šæ—¥æœŸæ˜¯å¦å·²å­˜åœ¨æ–¼ metadata è¨˜éŒ„çš„æ—¥æœŸç¯„åœå…§

        Args:
            securities_trader_id: åˆ¸å•†ä»£ç¢¼
            stock_id: è‚¡ç¥¨ä»£ç¢¼
            date: è¦æª¢æŸ¥çš„æ—¥æœŸ

        Returns:
            bool: True è¡¨ç¤ºæ—¥æœŸåœ¨ç¯„åœå…§ï¼ŒFalse è¡¨ç¤ºä¸åœ¨ç¯„åœå…§æˆ–æ²’æœ‰è¨˜éŒ„
        """
        # è½‰æ›æ—¥æœŸæ ¼å¼
        if isinstance(date, datetime.date):
            date_obj: datetime.date = date
        else:
            date_obj: datetime.date = datetime.datetime.strptime(
                str(date), "%Y-%m-%d"
            ).date()

        # å¾ metadata è®€å–æ—¥æœŸç¯„åœ
        metadata: Dict[str, Dict[str, Dict[str, str]]] = (
            self._load_broker_trading_metadata()
        )

        if (
            securities_trader_id not in metadata
            or stock_id not in metadata[securities_trader_id]
        ):
            return False

        stock_info: Dict[str, str] = metadata[securities_trader_id][stock_id]

        if "earliest_date" not in stock_info or "latest_date" not in stock_info:
            return False

        try:
            earliest_date: datetime.date = datetime.datetime.strptime(
                stock_info["earliest_date"], "%Y-%m-%d"
            ).date()
            latest_date: datetime.date = datetime.datetime.strptime(
                stock_info["latest_date"], "%Y-%m-%d"
            ).date()

            # æª¢æŸ¥æ—¥æœŸæ˜¯å¦åœ¨ç¯„åœå…§
            return earliest_date <= date_obj <= latest_date
        except (ValueError, KeyError) as e:
            logger.debug(f"Error checking date in metadata: {e}")
            return False

    def _get_existing_dates_from_metadata(
        self,
        securities_trader_id: str,
        stock_id: str,
    ) -> Set[str]:
        """
        å¾ metadata å–å¾—å·²å­˜åœ¨çš„æ—¥æœŸç¯„åœï¼Œä¸¦ç”Ÿæˆæ‰€æœ‰æ—¥æœŸ

        Args:
            securities_trader_id: åˆ¸å•†ä»£ç¢¼
            stock_id: è‚¡ç¥¨ä»£ç¢¼

        Returns:
            Set[str]: å·²å­˜åœ¨çš„æ—¥æœŸé›†åˆï¼ˆæ ¼å¼ç‚º "YYYY-MM-DD"ï¼‰
        """
        # å¾ metadata è®€å–æ—¥æœŸç¯„åœ
        metadata: Dict[str, Dict[str, Dict[str, str]]] = (
            self._load_broker_trading_metadata()
        )

        if (
            securities_trader_id not in metadata
            or stock_id not in metadata[securities_trader_id]
        ):
            return set()

        stock_info: Dict[str, str] = metadata[securities_trader_id][stock_id]

        if "earliest_date" not in stock_info or "latest_date" not in stock_info:
            return set()

        try:
            earliest_date: datetime.date = datetime.datetime.strptime(
                stock_info["earliest_date"], "%Y-%m-%d"
            ).date()
            latest_date: datetime.date = datetime.datetime.strptime(
                stock_info["latest_date"], "%Y-%m-%d"
            ).date()

            # ç”Ÿæˆæ—¥æœŸç¯„åœå…§çš„æ‰€æœ‰æ—¥æœŸ
            date_range: List[datetime.date] = TimeUtils.generate_date_range(
                earliest_date, latest_date
            )
            existing_dates: Set[str] = {d.strftime("%Y-%m-%d") for d in date_range}
            return existing_dates
        except (ValueError, KeyError) as e:
            logger.debug(f"Error getting dates from metadata: {e}")
            return set()
