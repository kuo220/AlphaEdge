import datetime
import json
import os
import sqlite3
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from unittest.mock import MagicMock, patch

import pandas as pd

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root: Path = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

# è¼‰å…¥ .env æª”æ¡ˆ
from dotenv import load_dotenv

env_path = project_root / ".env"
if env_path.exists():
    load_dotenv(dotenv_path=env_path)
else:
    load_dotenv()

from loguru import logger

# ç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²å¸¸æ•¸
STOCK_INFO_WITH_WARRANT_TABLE_NAME = "taiwan_stock_info_with_warrant"
SECURITIES_TRADER_INFO_TABLE_NAME = "taiwan_securities_trader_info"
STOCK_TRADING_DAILY_REPORT_TABLE_NAME = "taiwan_stock_trading_daily_report_secid_agg"


"""æ¸¬è©¦ FinMindUpdater broker trading æ›´æ–°ï¼šCSV åˆ†é¡ã€API è€—ç›¡æ¨¡æ“¬ã€æ¨¡æ“¬ DB å¯«å…¥"""


def create_mock_broker_trading_data(
    securities_trader_id: str,
    stock_id: str,
    start_date: datetime.date,
    end_date: datetime.date,
) -> pd.DataFrame:
    """å‰µå»ºæ¨¡æ“¬çš„åˆ¸å•†äº¤æ˜“è³‡æ–™"""
    dates = pd.date_range(start=start_date, end=end_date, freq="D")
    # åªä¿ç•™å·¥ä½œæ—¥ï¼ˆç°¡å–®è™•ç†ï¼Œå¯¦éš›æ‡‰è©²æ’é™¤å‡æ—¥ï¼‰
    dates = [d.date() for d in dates if d.weekday() < 5]

    data = []
    for date in dates:
        data.append(
            {
                "securities_trader": f"åˆ¸å•†_{securities_trader_id}",
                "securities_trader_id": securities_trader_id,
                "stock_id": stock_id,
                "date": date.strftime("%Y-%m-%d"),
                "buy_volume": 1000,
                "sell_volume": 800,
                "buy_price": 100.0,
                "sell_price": 101.0,
            }
        )

    return pd.DataFrame(data)


def setup_test_database(
    db_path: str, stock_list: List[str], trader_list: List[str]
) -> None:
    """è¨­ç½®æ¸¬è©¦è³‡æ–™åº«ï¼ŒåŒ…å«è‚¡ç¥¨å’Œåˆ¸å•†è³‡è¨Š"""
    conn = sqlite3.connect(db_path)

    # å‰µå»ºè‚¡ç¥¨è³‡è¨Šè¡¨
    conn.execute(
        f"""
        CREATE TABLE IF NOT EXISTS {STOCK_INFO_WITH_WARRANT_TABLE_NAME} (
            stock_id TEXT PRIMARY KEY,
            stock_name TEXT,
            industry_category TEXT,
            type TEXT,
            date TEXT
        )
        """
    )

    # æ’å…¥æ¸¬è©¦è‚¡ç¥¨
    for stock_id in stock_list:
        conn.execute(
            f"""
            INSERT OR REPLACE INTO {STOCK_INFO_WITH_WARRANT_TABLE_NAME}
            (stock_id, stock_name, industry_category, type, date)
            VALUES (?, ?, ?, ?, ?)
            """,
            (stock_id, f"è‚¡ç¥¨_{stock_id}", "é›»å­", "ä¸Šå¸‚", "2021-01-01"),
        )

    # å‰µå»ºåˆ¸å•†è³‡è¨Šè¡¨
    conn.execute(
        f"""
        CREATE TABLE IF NOT EXISTS {SECURITIES_TRADER_INFO_TABLE_NAME} (
            securities_trader_id TEXT PRIMARY KEY,
            securities_trader TEXT,
            date TEXT,
            address TEXT,
            phone TEXT
        )
        """
    )

    # æ’å…¥æ¸¬è©¦åˆ¸å•†
    for trader_id in trader_list:
        conn.execute(
            f"""
            INSERT OR REPLACE INTO {SECURITIES_TRADER_INFO_TABLE_NAME}
            (securities_trader_id, securities_trader, date, address, phone)
            VALUES (?, ?, ?, ?, ?)
            """,
            (trader_id, f"åˆ¸å•†_{trader_id}", "2021-01-01", "å°åŒ—å¸‚", "02-12345678"),
        )

    # å‰µå»ºåˆ¸å•†äº¤æ˜“å ±è¡¨è¡¨
    conn.execute(
        f"""
        CREATE TABLE IF NOT EXISTS {STOCK_TRADING_DAILY_REPORT_TABLE_NAME} (
            securities_trader TEXT,
            securities_trader_id TEXT,
            stock_id TEXT,
            date TEXT,
            buy_volume INTEGER,
            sell_volume INTEGER,
            buy_price REAL,
            sell_price REAL,
            PRIMARY KEY (securities_trader_id, stock_id, date)
        )
        """
    )

    conn.commit()
    conn.close()


def test_broker_trading_updater():
    """
    æ¸¬è©¦ broker trading daily report æ›´æ–°åŠŸèƒ½
    """
    print(f"\n{'='*60}")
    print(f"æ¸¬è©¦ Broker Trading Daily Report Updater")
    print(f"{'='*60}")

    # æ¸¬è©¦åƒæ•¸
    start_date = datetime.date(2021, 6, 30)
    end_date = datetime.date.today()
    test_stock_list = ["2330", "2317", "2454"]  # 3 æª”è‚¡ç¥¨
    test_trader_list = ["1020", "1021"]  # 2 é–“åˆ¸å•†

    print(f"\næ¸¬è©¦åƒæ•¸:")
    print(f"  - èµ·å§‹æ—¥æœŸ: {start_date}")
    print(f"  - çµæŸæ—¥æœŸ: {end_date}")
    print(f"  - è‚¡ç¥¨åˆ—è¡¨: {test_stock_list}")
    print(f"  - åˆ¸å•†åˆ—è¡¨: {test_trader_list}")

    # ä½¿ç”¨ tests/downloads ç›®éŒ„å­˜æ”¾æ¸¬è©¦è³‡æ–™ï¼ˆå›ºå®šçµæ§‹ï¼Œæ‰€æœ‰æ¸¬è©¦å…±ç”¨ï¼‰
    test_root = project_root / "tests" / "downloads"
    test_root.mkdir(parents=True, exist_ok=True)

    # è³‡æ–™åº«è·¯å¾‘ï¼ˆæ‰€æœ‰æ¸¬è©¦å…±ç”¨åŒä¸€å€‹è³‡æ–™åº«ï¼‰
    database_dir = project_root / "tests" / "database"
    database_dir.mkdir(parents=True, exist_ok=True)
    temp_db_path = str(database_dir / "test.db")

    # ä¸‹è¼‰ç›®éŒ„ï¼ˆç°¡åŒ–çµæ§‹ï¼šdownloads/finmindï¼‰
    temp_downloads_path = test_root / "finmind"
    temp_downloads_path.mkdir(parents=True, exist_ok=True)

    # metadata ç›®éŒ„ï¼ˆç°¡åŒ–çµæ§‹ï¼šdownloads/meta/broker_tradingï¼‰
    temp_metadata_path = test_root / "meta" / "broker_trading"
    temp_metadata_path.mkdir(parents=True, exist_ok=True)
    temp_metadata_file = temp_metadata_path / "broker_trading_metadata.json"

    print(f"\nğŸ“ æ¸¬è©¦è³‡æ–™ç›®éŒ„: {test_root}")
    print(f"   - è³‡æ–™åº«: {temp_db_path}")
    print(f"   - ä¸‹è¼‰ç›®éŒ„: {temp_downloads_path}")
    print(f"   - Metadata: {temp_metadata_file}")

    try:
        # è¨­ç½®æ¸¬è©¦è³‡æ–™åº«
        setup_test_database(temp_db_path, test_stock_list, test_trader_list)
        print("âœ… æ¸¬è©¦è³‡æ–™åº«è¨­ç½®å®Œæˆ")

        # Mock crawler çš„ crawl_broker_trading_daily_report æ–¹æ³•
        def mock_crawl_broker_trading_daily_report(
            stock_id: Optional[str] = None,
            securities_trader_id: Optional[str] = None,
            start_date: Optional[Any] = None,
            end_date: Optional[Any] = None,
        ) -> Optional[pd.DataFrame]:
            """æ¨¡æ“¬çˆ¬å–è³‡æ–™"""
            # è½‰æ›æ—¥æœŸæ ¼å¼
            if isinstance(start_date, str):
                start_date_obj = datetime.datetime.strptime(
                    start_date, "%Y-%m-%d"
                ).date()
            else:
                start_date_obj = start_date

            if isinstance(end_date, str):
                end_date_obj = datetime.datetime.strptime(end_date, "%Y-%m-%d").date()
            else:
                end_date_obj = end_date

            # å‰µå»ºæ¨¡æ“¬è³‡æ–™
            return create_mock_broker_trading_data(
                securities_trader_id=securities_trader_id,
                stock_id=stock_id,
                start_date=start_date_obj,
                end_date=end_date_obj,
            )

        # æ¸…é™¤å¯èƒ½å·²ç·©å­˜çš„æ¨¡çµ„
        modules_to_clear = [
            "trader.pipeline.updaters.finmind_updater",
            "trader.pipeline.loaders.finmind_loader",
            "trader.pipeline.cleaners.finmind_cleaner",
            "trader.pipeline.crawlers.finmind_crawler",
        ]
        for module_name in modules_to_clear:
            if module_name in sys.modules:
                del sys.modules[module_name]

        # Mock FinMind æ¨¡çµ„ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if "FinMind" not in sys.modules:
            finmind_mock = MagicMock()
            finmind_data_mock = MagicMock()
            finmind_data_mock.DataLoader = MagicMock
            finmind_mock.data = finmind_data_mock
            sys.modules["FinMind"] = finmind_mock
            sys.modules["FinMind.data"] = finmind_data_mock

        # ä½¿ç”¨ patch æ›¿æ›é…ç½®ï¼ˆåœ¨å°å…¥å‰ patchï¼‰
        with patch("trader.config.DB_PATH", temp_db_path), patch(
            "trader.config.FINMIND_DOWNLOADS_PATH", temp_downloads_path
        ), patch("trader.config.BROKER_TRADING_METADATA_PATH", temp_metadata_file):
            # å°å…¥ updaterï¼ˆåœ¨ patch å¾Œå°å…¥ï¼Œé€™æ¨£æœƒä½¿ç”¨ patch å¾Œçš„å€¼ï¼‰
            from trader.pipeline.updaters.finmind_updater import FinMindUpdater

            updater = FinMindUpdater()

            # Mock crawler æ–¹æ³•
            updater.crawler.crawl_broker_trading_daily_report = (
                mock_crawl_broker_trading_daily_report
            )

            # ===== æ¸¬è©¦ 1: æ¸¬è©¦å–®ä¸€çµ„åˆæ›´æ–° (update_broker_trading_daily_report) =====
            print(f"\n{'='*60}")
            print("æ¸¬è©¦ 1: update_broker_trading_daily_report() - å–®ä¸€çµ„åˆæ›´æ–°")
            print(f"{'='*60}")

            test_stock_id = test_stock_list[0]
            test_trader_id = test_trader_list[0]

            print(f"\næ¸¬è©¦åƒæ•¸:")
            print(f"  - è‚¡ç¥¨ä»£ç¢¼: {test_stock_id}")
            print(f"  - åˆ¸å•†ä»£ç¢¼: {test_trader_id}")
            print(f"  - æ—¥æœŸç¯„åœ: {start_date} ~ {end_date}")

            # åŸ·è¡Œæ›´æ–°
            status = updater.update_broker_trading_daily_report(
                stock_id=test_stock_id,
                securities_trader_id=test_trader_id,
                start_date=start_date,
                end_date=end_date,
            )

            print(f"\næ›´æ–°ç‹€æ…‹: {status}")

            # é©—è­‰ CSV æª”æ¡ˆæ˜¯å¦å­˜åœ¨ä¸”çµæ§‹æ­£ç¢º
            csv_path = (
                temp_downloads_path
                / "broker_trading"
                / test_trader_id
                / f"{test_stock_id}.csv"
            )

            assert csv_path.exists(), f"CSV æª”æ¡ˆä¸å­˜åœ¨: {csv_path}"

            # è®€å– CSV æª”æ¡ˆ
            df_csv = pd.read_csv(csv_path, encoding="utf-8-sig")
            print(f"\nâœ… CSV æª”æ¡ˆé©—è­‰é€šé:")
            print(f"  - è·¯å¾‘: {csv_path}")
            print(f"  - è³‡æ–™ç­†æ•¸: {len(df_csv)}")
            print(f"  - æ¬„ä½: {list(df_csv.columns)}")

            # é©—è­‰è³‡æ–™åº«ä¸­çš„è³‡æ–™
            conn = sqlite3.connect(temp_db_path)
            query = f"""
            SELECT COUNT(*) FROM {STOCK_TRADING_DAILY_REPORT_TABLE_NAME}
            WHERE stock_id = ? AND securities_trader_id = ?
            """
            cursor = conn.cursor()
            cursor.execute(query, (test_stock_id, test_trader_id))
            db_count = cursor.fetchone()[0]

            print(f"\nâœ… è³‡æ–™åº«é©—è­‰:")
            print(f"  - è³‡æ–™ç­†æ•¸: {db_count}")

            # é©—è­‰è³‡æ–™ä¸€è‡´æ€§
            assert db_count > 0, "è³‡æ–™åº«ä¸­æ²’æœ‰è³‡æ–™"
            assert db_count == len(df_csv), "CSV å’Œè³‡æ–™åº«çš„è³‡æ–™ç­†æ•¸ä¸ä¸€è‡´"

            conn.close()

            # ===== æ¸¬è©¦ 2: æ¸¬è©¦æ‰¹é‡æ›´æ–° (update_broker_trading_daily_report) =====
            print(f"\n{'='*60}")
            print("æ¸¬è©¦ 2: update_broker_trading_daily_report() - æ‰¹é‡æ›´æ–°")
            print(f"{'='*60}")

            # æ¸¬è©¦ 2 ä½¿ç”¨ç›¸åŒçš„è³‡æ–™åº«å’Œç›®éŒ„ï¼ˆæ¸…ç©ºè³‡æ–™åº«é‡æ–°é–‹å§‹ï¼‰
            # å…ˆåˆªé™¤ç¾æœ‰è³‡æ–™åº«ä»¥ç¢ºä¿ä¹¾æ·¨çš„æ¸¬è©¦ç’°å¢ƒ
            if os.path.exists(temp_db_path):
                os.remove(temp_db_path)

            setup_test_database(temp_db_path, test_stock_list, test_trader_list)

            # æ¸…é™¤æ¨¡çµ„ç·©å­˜
            modules_to_clear = [
                "trader.pipeline.updaters.finmind_updater",
                "trader.pipeline.loaders.finmind_loader",
                "trader.pipeline.cleaners.finmind_cleaner",
                "trader.pipeline.crawlers.finmind_crawler",
            ]
            for module_name in modules_to_clear:
                if module_name in sys.modules:
                    del sys.modules[module_name]

            with patch("trader.config.DB_PATH", temp_db_path), patch(
                "trader.config.FINMIND_DOWNLOADS_PATH", temp_downloads_path
            ), patch("trader.config.BROKER_TRADING_METADATA_PATH", temp_metadata_file):
                from trader.pipeline.updaters.finmind_updater import FinMindUpdater

                updater2 = FinMindUpdater()
                updater2.crawler.crawl_broker_trading_daily_report = (
                    mock_crawl_broker_trading_daily_report
                )

                # é‡ç½® API quota è¨ˆæ•¸å™¨
                updater2.api_call_count = 0
                updater2.api_quota_limit = 100  # è¨­ç½®è¼ƒå°çš„ quota ä»¥ä¾¿æ¸¬è©¦è€—ç›¡æƒ…æ³

                print(f"\nAPI Quota è¨­å®š:")
                print(f"  - é™åˆ¶: {updater2.api_quota_limit}")
                print(f"  - ç•¶å‰ä½¿ç”¨: {updater2.api_call_count}")

                # åŸ·è¡Œæ‰¹é‡æ›´æ–°
                print(f"\nğŸ”„ åŸ·è¡Œæ‰¹é‡æ›´æ–°...")
                updater2.update_broker_trading_daily_report(
                    start_date=start_date, end_date=end_date
                )

                # é©—è­‰æ‰€æœ‰çµ„åˆçš„ CSV æª”æ¡ˆ
                print(f"\nâœ… CSV æª”æ¡ˆçµæ§‹é©—è­‰:")
                broker_trading_dir = temp_downloads_path / "broker_trading"
                assert broker_trading_dir.exists(), "broker_trading ç›®éŒ„ä¸å­˜åœ¨"

                csv_files_found = []
                for trader_id in test_trader_list:
                    trader_dir = broker_trading_dir / trader_id
                    if not trader_dir.exists():
                        print(f"  âš ï¸  åˆ¸å•†ç›®éŒ„ä¸å­˜åœ¨: {trader_dir}ï¼ˆå¯èƒ½æ²’æœ‰è³‡æ–™ï¼‰")
                        continue

                    for stock_id in test_stock_list:
                        csv_file = trader_dir / f"{stock_id}.csv"
                        if csv_file.exists():
                            csv_files_found.append((trader_id, stock_id))
                            df = pd.read_csv(csv_file, encoding="utf-8-sig")
                            print(f"  âœ… {trader_id}/{stock_id}.csv: {len(df)} ç­†è³‡æ–™")

                print(f"\næ‰¾åˆ° {len(csv_files_found)} å€‹ CSV æª”æ¡ˆ")

                # é©—è­‰è³‡æ–™åº«ä¸­çš„è³‡æ–™
                conn = sqlite3.connect(temp_db_path)
                query = f"SELECT COUNT(*) FROM {STOCK_TRADING_DAILY_REPORT_TABLE_NAME}"
                cursor = conn.cursor()
                cursor.execute(query)
                total_db_count = cursor.fetchone()[0]

                print(f"\nâœ… è³‡æ–™åº«ç¸½è³‡æ–™ç­†æ•¸: {total_db_count}")

                # é©—è­‰æ¯å€‹çµ„åˆçš„è³‡æ–™
                for trader_id in test_trader_list:
                    for stock_id in test_stock_list:
                        query = f"""
                        SELECT COUNT(*) FROM {STOCK_TRADING_DAILY_REPORT_TABLE_NAME}
                        WHERE stock_id = ? AND securities_trader_id = ?
                        """
                        cursor.execute(query, (stock_id, trader_id))
                        count = cursor.fetchone()[0]
                        if count > 0:
                            print(f"  âœ… {trader_id}/{stock_id}: {count} ç­†è³‡æ–™")

                conn.close()

            # ===== æ¸¬è©¦ 3: æ¨¡æ“¬ API è€—ç›¡çš„æƒ…æ³ =====
            print(f"\n{'='*60}")
            print("æ¸¬è©¦ 3: æ¨¡æ“¬ API è€—ç›¡çš„æƒ…æ³")
            print(f"{'='*60}")

            # æ¸¬è©¦ 3 ä½¿ç”¨ç›¸åŒçš„è³‡æ–™åº«å’Œç›®éŒ„ï¼ˆæ¸…ç©ºè³‡æ–™åº«é‡æ–°é–‹å§‹ï¼‰
            # å…ˆåˆªé™¤ç¾æœ‰è³‡æ–™åº«ä»¥ç¢ºä¿ä¹¾æ·¨çš„æ¸¬è©¦ç’°å¢ƒ
            if os.path.exists(temp_db_path):
                os.remove(temp_db_path)

            setup_test_database(temp_db_path, test_stock_list, test_trader_list)

            # æ¸…é™¤å¯èƒ½å·²ç·©å­˜çš„æ¨¡çµ„
            modules_to_clear = [
                "trader.pipeline.updaters.finmind_updater",
                "trader.pipeline.loaders.finmind_loader",
                "trader.pipeline.cleaners.finmind_cleaner",
                "trader.pipeline.crawlers.finmind_crawler",
            ]
            for module_name in modules_to_clear:
                if module_name in sys.modules:
                    del sys.modules[module_name]

            with patch("trader.config.DB_PATH", temp_db_path), patch(
                "trader.config.FINMIND_DOWNLOADS_PATH", temp_downloads_path
            ), patch("trader.config.BROKER_TRADING_METADATA_PATH", temp_metadata_file):
                # é‡æ–°å°å…¥ updater
                from trader.pipeline.updaters.finmind_updater import FinMindUpdater

                updater2 = FinMindUpdater()
                updater2.crawler.crawl_broker_trading_daily_report = (
                    mock_crawl_broker_trading_daily_report
                )

                # ä½¿ç”¨è¨ˆæ•¸å™¨ä¾†è¿½è¹¤è™•ç†çš„çµ„åˆæ•¸
                processed_count = [0]  # ä½¿ç”¨åˆ—è¡¨ä»¥ä¾¿åœ¨é–‰åŒ…ä¸­ä¿®æ”¹

                # ä¿å­˜åŸå§‹çš„ _check_and_update_api_quota æ–¹æ³•
                original_check_quota = updater2._check_and_update_api_quota

                def mock_check_and_update_api_quota() -> bool:
                    """æ¨¡æ“¬ quota æª¢æŸ¥ï¼Œåœ¨è™•ç† 2 å€‹çµ„åˆå¾Œè§¸ç™¼è€—ç›¡"""
                    processed_count[0] += 1
                    if processed_count[0] <= 2:
                        # å‰ 2 å€‹çµ„åˆæ­£å¸¸è™•ç†
                        return original_check_quota()
                    else:
                        # ç¬¬ 3 å€‹çµ„åˆé–‹å§‹è§¸ç™¼è€—ç›¡
                        print(
                            f"  âš ï¸  å·²è™•ç† {processed_count[0]} å€‹çµ„åˆï¼Œè§¸ç™¼ API quota è€—ç›¡æª¢æŸ¥"
                        )
                        return False

                updater2._check_and_update_api_quota = mock_check_and_update_api_quota

                # è¨­ç½® API quota
                updater2.api_quota_limit = 100
                updater2.api_call_count = 0

                print(f"\nAPI Quota è¨­å®š:")
                print(f"  - é™åˆ¶: {updater2.api_quota_limit}")
                print(f"  - ç•¶å‰ä½¿ç”¨: {updater2.api_call_count}")
                print(f"  - æ¸¬è©¦ç­–ç•¥: è™•ç† 2 å€‹çµ„åˆå¾Œè§¸ç™¼ quota è€—ç›¡")

                # Mock _wait_for_quota_reset ä¾†é¿å…çœŸçš„ç­‰å¾…
                def mock_wait_for_quota_reset(
                    check_interval_minutes: int = 10,
                    max_wait_minutes: Optional[int] = None,
                ) -> bool:
                    """æ¨¡æ“¬ç­‰å¾… quota é‡ç½®ï¼ˆç«‹å³è¿”å› False ä»¥æ¸¬è©¦è€—ç›¡æƒ…æ³ï¼‰"""
                    print("  âš ï¸  API quota è€—ç›¡ï¼Œæ¨¡æ“¬ç­‰å¾…å¤±æ•—ï¼ˆæ¸¬è©¦ç›®çš„ï¼‰")
                    return False  # æ¨¡æ“¬ç­‰å¾…è¶…æ™‚

                updater2._wait_for_quota_reset = mock_wait_for_quota_reset

                # åŸ·è¡Œæ‰¹é‡æ›´æ–°ï¼ˆæ‡‰è©²æœƒåœ¨è™•ç† 2 å€‹çµ„åˆå¾Œåœæ­¢ï¼‰
                print(f"\nğŸ”„ åŸ·è¡Œæ‰¹é‡æ›´æ–°ï¼ˆé æœŸè™•ç† 2 å€‹çµ„åˆå¾Œè€—ç›¡ quotaï¼‰...")
                updater2.update_broker_trading_daily_report(
                    start_date=start_date, end_date=end_date
                )

                print(f"  âœ… æ‰¹é‡æ›´æ–°å·²åœæ­¢ï¼ˆå·²è™•ç† {processed_count[0]} å€‹çµ„åˆï¼‰")

                # é©—è­‰ metadata JSON æª”æ¡ˆæ˜¯å¦å­˜åœ¨ä¸”æœ‰è¨˜éŒ„
                assert (
                    temp_metadata_file.exists()
                ), "Metadata JSON æª”æ¡ˆä¸å­˜åœ¨ï¼ˆæ‡‰è©²åœ¨ quota è€—ç›¡å‰ä¿å­˜ï¼‰"

                # è®€å– metadata
                with open(temp_metadata_file, "r", encoding="utf-8") as f:
                    metadata = json.load(f)

                print(f"\nâœ… Metadata JSON æª”æ¡ˆé©—è­‰:")
                print(f"  - è·¯å¾‘: {temp_metadata_file}")
                print(f"  - è¨˜éŒ„çš„çµ„åˆæ•¸: {len(metadata)}")

                # é¡¯ç¤º metadata å…§å®¹
                for broker_id, stocks in metadata.items():
                    print(f"  - åˆ¸å•† {broker_id}:")
                    for stock_id, date_range in stocks.items():
                        print(
                            f"    - è‚¡ç¥¨ {stock_id}: {date_range.get('earliest_date')} ~ {date_range.get('latest_date')}"
                        )

                # é©—è­‰è‡³å°‘æœ‰ä¸€äº›è¨˜éŒ„
                total_combinations = sum(len(stocks) for stocks in metadata.values())
                print(f"\n  ç¸½å…±è¨˜éŒ„äº† {total_combinations} å€‹çµ„åˆçš„æ—¥æœŸç¯„åœ")

                # é©—è­‰è‡³å°‘æœ‰ä¸€äº›è¨˜éŒ„ï¼ˆç”±æ–¼è™•ç†äº† 2 å€‹çµ„åˆï¼Œæ‡‰è©²è‡³å°‘æœ‰ 1-2 å€‹è¨˜éŒ„ï¼‰
                assert total_combinations > 0, "Metadata ä¸­æ‡‰è©²è‡³å°‘æœ‰ä¸€äº›è¨˜éŒ„"

                # é©—è­‰ metadata çµæ§‹æ­£ç¢ºï¼ˆæ¯å€‹çµ„åˆéƒ½æ‡‰è©²æœ‰ earliest_date å’Œ latest_dateï¼‰
                for broker_id, stocks in metadata.items():
                    for stock_id, date_range in stocks.items():
                        assert (
                            "earliest_date" in date_range
                        ), f"ç¼ºå°‘ earliest_date: {broker_id}/{stock_id}"
                        assert (
                            "latest_date" in date_range
                        ), f"ç¼ºå°‘ latest_date: {broker_id}/{stock_id}"
                        print(f"  âœ… {broker_id}/{stock_id}: æ—¥æœŸç¯„åœå®Œæ•´")

                # é©—è­‰ CSV æª”æ¡ˆï¼ˆæª¢æŸ¥å·²è™•ç†çš„çµ„åˆæ˜¯å¦æœ‰ CSV æª”æ¡ˆï¼‰
                print(f"\nâœ… CSV æª”æ¡ˆé©—è­‰ï¼ˆquota è€—ç›¡å‰è™•ç†çš„è³‡æ–™ï¼‰:")
                broker_trading_dir = temp_downloads_path / "broker_trading"
                if broker_trading_dir.exists():
                    csv_count = 0
                    for trader_dir in broker_trading_dir.iterdir():
                        if trader_dir.is_dir():
                            for csv_file in trader_dir.glob("*.csv"):
                                csv_count += 1
                                df = pd.read_csv(csv_file, encoding="utf-8-sig")
                                print(
                                    f"  âœ… {csv_file.parent.name}/{csv_file.name}: {len(df)} ç­†è³‡æ–™"
                                )
                    print(f"  ç¸½å…±æ‰¾åˆ° {csv_count} å€‹ CSV æª”æ¡ˆ")
                else:
                    print("  âš ï¸  broker_trading ç›®éŒ„ä¸å­˜åœ¨ï¼ˆå¯èƒ½æ²’æœ‰è™•ç†ä»»ä½•çµ„åˆï¼‰")

                # é©—è­‰è³‡æ–™åº«ä¸­çš„è³‡æ–™
                print(f"\nâœ… è³‡æ–™åº«é©—è­‰ï¼ˆquota è€—ç›¡å‰è™•ç†çš„è³‡æ–™ï¼‰:")
                conn = sqlite3.connect(temp_db_path)
                query = f"SELECT COUNT(*) FROM {STOCK_TRADING_DAILY_REPORT_TABLE_NAME}"
                cursor = conn.cursor()
                cursor.execute(query)
                db_count = cursor.fetchone()[0]
                print(f"  - è³‡æ–™åº«ç¸½è³‡æ–™ç­†æ•¸: {db_count}")
                conn.close()

            print(f"\n{'='*60}")
            print("âœ… æ‰€æœ‰æ¸¬è©¦é€šéï¼")
            print(f"{'='*60}")
            print(f"\nğŸ“ æ¸¬è©¦çµæœ:")
            print(f"  - æ¸¬è©¦è³‡æ–™ç›®éŒ„: {test_root}")
            print(f"  - CSV æª”æ¡ˆçµæ§‹: âœ… æ­£ç¢º")
            print(f"  - è³‡æ–™åº«è³‡æ–™: âœ… æ­£ç¢º")
            print(f"  - Metadata JSON: âœ… æ­£ç¢ºè¨˜éŒ„")
            print(f"\nğŸ’¡ æç¤º:")
            print(f"  - æ‰€æœ‰æ¸¬è©¦è³‡æ–™å·²ä¿å­˜åœ¨: {test_root}")
            print(f"  - CSV æª”æ¡ˆå·²ä¿ç•™ï¼Œå¯ä»¥æ‰‹å‹•æª¢æŸ¥")
            print(f"  - æ¸¬è©¦è³‡æ–™åº«ä½ç½®: tests/database/test.db")
            print(f"  - ä¸‹è¼‰è³‡æ–™ä½ç½®: {test_root}/finmind/broker_trading/")
            print(f"  - Metadata ä½ç½®: {test_root}/meta/broker_trading/")

            return True

    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback

        traceback.print_exc()
        return False

    finally:
        # ä¿ç•™æ‰€æœ‰æ¸¬è©¦è³‡æ–™ï¼ˆä¸åˆªé™¤ï¼‰
        # æ¸¬è©¦è³‡æ–™å·²ä¿å­˜åœ¨ tests/downloads/ ç›®éŒ„ä¸­
        pass


if __name__ == "__main__":
    # è¨­å®š logger
    logger.remove()
    logger.add(lambda msg: print(msg, end=""), format="{message}")

    # åŸ·è¡Œæ¸¬è©¦
    success = test_broker_trading_updater()

    if success:
        print("\nğŸ‰ æ¸¬è©¦å®Œæˆï¼")
    else:
        print("\nâš ï¸  æ¸¬è©¦æœªå®Œå…¨æˆåŠŸï¼Œè«‹æª¢æŸ¥ä¸Šè¿°è¼¸å‡º")
